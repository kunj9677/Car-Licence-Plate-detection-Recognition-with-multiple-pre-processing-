{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGe5wB5lBt5q"
      },
      "source": [
        "# Automatic Number Plate Recognition System"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dependencies"
      ],
      "metadata": {
        "id": "jeRop1riHn4b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1XPtd_cBt5r"
      },
      "source": [
        "**Note**: Newer Python versions require users to install dependencies in a virtual environment. Learn how to create a virtual environment [here](https://docs.python.org/3/library/venv.html), or if using Visual Studio Code, [here](https://code.visualstudio.com/docs/python/environments)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_XK7X2IrWJ2",
        "outputId": "9f2ae7ce-01d8-40e6-c944-84857469f290"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "cNZxnH33Mp01"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WN-zIjYptJLf",
        "outputId": "64dd29db-3590-4b06-a3c9-41b54f9133d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.24)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.9)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics scikit-learn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "LJY_Zceosy7m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import xml.etree.ElementTree as xet\n",
        "import cv2\n",
        "import re\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TXQ4RyaBt5t"
      },
      "source": [
        "Make sure CUDA is available. CUDA is a program created by Nvidia that gives PyTorch direct access to the GPU, making processing way more efficient. CUDA cores (or devices) are computer cores that are specialised for parallel computing. If there aren't any CUDA cores available, it's probably because you're running the notebook on a CPU, not a GPU. Google Colab offers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8223X9mtDk8",
        "outputId": "6339dadf-72b2-44b4-82a7-ce038104b833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.cuda.is_available() = True\n",
            "torch.cuda.device_count() = 1\n"
          ]
        }
      ],
      "source": [
        "print(f'{torch.cuda.is_available() = }')\n",
        "print(f'{torch.cuda.device_count() = }')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preprocessing"
      ],
      "metadata": {
        "id": "_oV7jItaJRdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Define preprocessing"
      ],
      "metadata": {
        "id": "jXmr-sgFLXTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian Blur to reduce noise\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 1.4)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blurred_image, threshold1=100, threshold2=200)\n",
        "\n",
        "    return edges"
      ],
      "metadata": {
        "id": "30ccGMLjJQV0"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(input_dir, output_dir):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get list of all image files\n",
        "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png'))]\n",
        "\n",
        "    # Process each image\n",
        "    for filename in tqdm(image_files, desc=\"Processing images\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_dir, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error reading image: {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Preprocess the image\n",
        "        processed_image = preprocess_image(image)\n",
        "\n",
        "        # Save the processed image\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "        cv2.imwrite(output_path, processed_image)"
      ],
      "metadata": {
        "id": "BAy6goyvM0f2"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Preprocess images in dataset"
      ],
      "metadata": {
        "id": "uRV9WMoTLaA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"drive/MyDrive/dataset\"\n",
        "input_directory = f\"{dir}/images\"\n",
        "output_directory = \"dataset/preprocessed_images\"\n",
        "dataset_path = \"dataset\""
      ],
      "metadata": {
        "id": "M9uIxscILeni"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_dataset(input_directory, output_directory)"
      ],
      "metadata": {
        "id": "Ups_GQjAlNZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4942f857-9c2e-42c3-ad0e-a600e5a34267"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 433/433 [00:19<00:00, 22.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data"
      ],
      "metadata": {
        "id": "E7rqKrRhJC2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Find data"
      ],
      "metadata": {
        "id": "3IV7NiZSHs8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy over images\n",
        "import shutil\n",
        "try:\n",
        "    shutil.copyfile(f\"{dir}/datasets.yaml\", f\"{dataset_path}/datasets.yaml\")\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "try:\n",
        "    shutil.copytree(f\"{dir}/images\", f\"{dataset_path}/images\")\n",
        "except FileExistsError:\n",
        "    pass\n",
        "try:\n",
        "    shutil.copytree(f\"{dir}/preprocessed_images\", f\"{dataset_path}/preprocessed_images\")\n",
        "except FileExistsError:\n",
        "    pass\n",
        "try:\n",
        "    shutil.copytree(f\"{dir}/annotations\", f\"{dataset_path}/annotations\")\n",
        "except FileExistsError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "7tn7wRWOxQjs"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "a5C-EMndtccy"
      },
      "outputs": [],
      "source": [
        "def extract_number_from_str(filename):\n",
        "    \"\"\"Function to find a given image or label number to adjoin images and labels together.\"\"\"\n",
        "    match = re.search(r'(\\d+)', filename)\n",
        "\n",
        "    if match:\n",
        "        return int(match.group(0))\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "Ktsce1UTtmG6"
      },
      "outputs": [],
      "source": [
        "# Store labels and image info\n",
        "labels_dict = dict(\n",
        "    img_path=[],\n",
        "    xmin=[],\n",
        "    xmax=[],\n",
        "    ymin=[],\n",
        "    ymax=[],\n",
        "    img_w=[],\n",
        "    img_h=[]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "collapsed": true,
        "id": "lbSp7UjFtrDu"
      },
      "outputs": [],
      "source": [
        "# get XML files from the annotations dir\n",
        "xml_files = glob(f'{dataset_path}/annotations/*.xml')\n",
        "assert xml_files, \"Couldn't find dataset. Make sure to upload the dataset to Colab.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "-LL7o6LmyvLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e6f0986c-87a8-45e7-b17a-3567a4a57805"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    img_path  xmin  xmax  ymin  ymax  img_w  \\\n",
              "0      dataset/preprocessed_images/Cars0.png   226   419   125   173    500   \n",
              "1      dataset/preprocessed_images/Cars1.png   134   262   128   160    400   \n",
              "2      dataset/preprocessed_images/Cars2.png   229   270   176   193    400   \n",
              "3      dataset/preprocessed_images/Cars3.png   142   261   128   157    400   \n",
              "4      dataset/preprocessed_images/Cars4.png   156   503    82   253    590   \n",
              "..                                       ...   ...   ...   ...   ...    ...   \n",
              "428  dataset/preprocessed_images/Cars428.png   142   258   128   157    400   \n",
              "429  dataset/preprocessed_images/Cars429.png    86   208   166   195    301   \n",
              "430  dataset/preprocessed_images/Cars430.png    38   116   159   197    400   \n",
              "431  dataset/preprocessed_images/Cars431.png    55   343    82   147    400   \n",
              "432  dataset/preprocessed_images/Cars432.png    95   196   258   284    467   \n",
              "\n",
              "     img_h  \n",
              "0      268  \n",
              "1      248  \n",
              "2      400  \n",
              "3      225  \n",
              "4      350  \n",
              "..     ...  \n",
              "428    225  \n",
              "429    400  \n",
              "430    225  \n",
              "431    192  \n",
              "432    300  \n",
              "\n",
              "[433 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-763dad25-b6cf-4807-b4c1-499a2ba32e67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>xmin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymin</th>\n",
              "      <th>ymax</th>\n",
              "      <th>img_w</th>\n",
              "      <th>img_h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dataset/preprocessed_images/Cars0.png</td>\n",
              "      <td>226</td>\n",
              "      <td>419</td>\n",
              "      <td>125</td>\n",
              "      <td>173</td>\n",
              "      <td>500</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dataset/preprocessed_images/Cars1.png</td>\n",
              "      <td>134</td>\n",
              "      <td>262</td>\n",
              "      <td>128</td>\n",
              "      <td>160</td>\n",
              "      <td>400</td>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dataset/preprocessed_images/Cars2.png</td>\n",
              "      <td>229</td>\n",
              "      <td>270</td>\n",
              "      <td>176</td>\n",
              "      <td>193</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dataset/preprocessed_images/Cars3.png</td>\n",
              "      <td>142</td>\n",
              "      <td>261</td>\n",
              "      <td>128</td>\n",
              "      <td>157</td>\n",
              "      <td>400</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dataset/preprocessed_images/Cars4.png</td>\n",
              "      <td>156</td>\n",
              "      <td>503</td>\n",
              "      <td>82</td>\n",
              "      <td>253</td>\n",
              "      <td>590</td>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>dataset/preprocessed_images/Cars428.png</td>\n",
              "      <td>142</td>\n",
              "      <td>258</td>\n",
              "      <td>128</td>\n",
              "      <td>157</td>\n",
              "      <td>400</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>dataset/preprocessed_images/Cars429.png</td>\n",
              "      <td>86</td>\n",
              "      <td>208</td>\n",
              "      <td>166</td>\n",
              "      <td>195</td>\n",
              "      <td>301</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>dataset/preprocessed_images/Cars430.png</td>\n",
              "      <td>38</td>\n",
              "      <td>116</td>\n",
              "      <td>159</td>\n",
              "      <td>197</td>\n",
              "      <td>400</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>dataset/preprocessed_images/Cars431.png</td>\n",
              "      <td>55</td>\n",
              "      <td>343</td>\n",
              "      <td>82</td>\n",
              "      <td>147</td>\n",
              "      <td>400</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>dataset/preprocessed_images/Cars432.png</td>\n",
              "      <td>95</td>\n",
              "      <td>196</td>\n",
              "      <td>258</td>\n",
              "      <td>284</td>\n",
              "      <td>467</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>433 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-763dad25-b6cf-4807-b4c1-499a2ba32e67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-763dad25-b6cf-4807-b4c1-499a2ba32e67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-763dad25-b6cf-4807-b4c1-499a2ba32e67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5c5cf35-431a-40a6-a082-17384ec64677\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5c5cf35-431a-40a6-a082-17384ec64677')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5c5cf35-431a-40a6-a082-17384ec64677 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fda29d5a-514d-41cb-9648-77579f1d9b4a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('alldata')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fda29d5a-514d-41cb-9648-77579f1d9b4a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('alldata');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "alldata",
              "summary": "{\n  \"name\": \"alldata\",\n  \"rows\": 433,\n  \"fields\": [\n    {\n      \"column\": \"img_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 433,\n        \"samples\": [\n          \"dataset/preprocessed_images/Cars425.png\",\n          \"dataset/preprocessed_images/Cars75.png\",\n          \"dataset/preprocessed_images/Cars181.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xmin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 82,\n        \"min\": 0,\n        \"max\": 541,\n        \"num_unique_values\": 218,\n        \"samples\": [\n          247,\n          211,\n          59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xmax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92,\n        \"min\": 27,\n        \"max\": 598,\n        \"num_unique_values\": 235,\n        \"samples\": [\n          326,\n          107,\n          253\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ymin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 5,\n        \"max\": 405,\n        \"num_unique_values\": 180,\n        \"samples\": [\n          165,\n          117,\n          282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ymax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 65,\n        \"max\": 439,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          76,\n          167,\n          123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68,\n        \"min\": 225,\n        \"max\": 600,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          530,\n          375,\n          370\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_h\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 66,\n        \"min\": 141,\n        \"max\": 531,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          242,\n          478,\n          223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "# Process each XML file, sorted by the numerical value in the filename\n",
        "for filename in sorted(xml_files, key=extract_number_from_str):\n",
        "\n",
        "    info = xet.parse(filename)\n",
        "    root = info.getroot()\n",
        "\n",
        "    # Extract bounding box coordinates\n",
        "    member_object = root.find('object')\n",
        "    labels_info = member_object.find('bndbox')\n",
        "    xmin = int(labels_info.find('xmin').text)\n",
        "    xmax = int(labels_info.find('xmax').text)\n",
        "    ymin = int(labels_info.find('ymin').text)\n",
        "    ymax = int(labels_info.find('ymax').text)\n",
        "\n",
        "    # join full path\n",
        "    img_name = root.find('filename').text\n",
        "    img_path = os.path.join(dataset_path, 'preprocessed_images', img_name)\n",
        "\n",
        "    # add to dictionary\n",
        "    labels_dict['img_path'].append(img_path)\n",
        "    labels_dict['xmin'].append(xmin)\n",
        "    labels_dict['xmax'].append(xmax)\n",
        "    labels_dict['ymin'].append(ymin)\n",
        "    labels_dict['ymax'].append(ymax)\n",
        "\n",
        "    # Read img and get dimensions\n",
        "    height, width, _ = cv2.imread(img_path).shape\n",
        "    labels_dict['img_w'].append(width)\n",
        "    labels_dict['img_h'].append(height)\n",
        "\n",
        "    alldata = pd.DataFrame(labels_dict)\n",
        "\n",
        "alldata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Split data"
      ],
      "metadata": {
        "id": "OyEh7T5GJLO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "Lye48gNy9Bfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f91248f-0c8d-4813-e756-e8e520cea93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of images in each set\n",
            "Training:   345 images\n",
            "Validation:  44 images\n",
            "Testing:     44 images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Split dataset for training, testing and validation\n",
        "train, test = train_test_split(alldata, test_size=1/10, random_state=42)\n",
        "train, val = train_test_split(train, train_size=8/9, random_state=42)\n",
        "\n",
        "print(f'''\n",
        "Number of images in each set\n",
        "Training:   {len(train)} images\n",
        "Validation:  {len(val)} images\n",
        "Testing:     {len(test)} images\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1i8DUsc9RVY"
      },
      "source": [
        "## 3.3 Convert data to YOLO format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "pr8KxY7t9LMg"
      },
      "outputs": [],
      "source": [
        "def make_split_folder_in_yolo_format(split_name, split_df):\n",
        "    # folders in YOLO format\n",
        "    labels_path = os.path.join('datasets', 'cars_license_plates', split_name, 'labels')\n",
        "    images_path = os.path.join('datasets', 'cars_license_plates', split_name, 'images')\n",
        "\n",
        "    if not os.path.exists(labels_path):\n",
        "        os.makedirs(labels_path)\n",
        "        os.makedirs(images_path)\n",
        "\n",
        "    for _, row in split_df.iterrows():\n",
        "        img_name, img_extension = os.path.splitext(os.path.basename(row['img_path']))\n",
        "\n",
        "        x_center = (row['xmin'] + row['xmax']) / 2 / row['img_w']\n",
        "        y_center = (row['ymin'] + row['ymax']) / 2 / row['img_h']\n",
        "        width = (row['xmax'] - row['xmin']) / row['img_w']\n",
        "        height = (row['ymax'] - row['ymin']) / row['img_h']\n",
        "\n",
        "        # save lables in YOLO format\n",
        "        label_path = os.path.join(labels_path, f'{img_name}.txt')\n",
        "        with open(label_path, 'w') as file:\n",
        "            file.write(f\"0 {x_center:.4f} {y_center:.4f} {width:.4f} {height:.4f}\\n\")\n",
        "\n",
        "\n",
        "        shutil.copy(row['img_path'], os.path.join(images_path, img_name + img_extension))\n",
        "\n",
        "    print(f\"Created '{images_path}' and '{labels_path}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "collapsed": true,
        "id": "e93i1XyZ9ajt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf2c526-c94f-41c5-de4c-46ec80cd947f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 'datasets/cars_license_plates/train/images' and 'datasets/cars_license_plates/train/labels'\n",
            "Created 'datasets/cars_license_plates/val/images' and 'datasets/cars_license_plates/val/labels'\n",
            "Created 'datasets/cars_license_plates/test/images' and 'datasets/cars_license_plates/test/labels'\n"
          ]
        }
      ],
      "source": [
        "make_split_folder_in_yolo_format(\"train\", train)\n",
        "make_split_folder_in_yolo_format(\"val\", val)\n",
        "make_split_folder_in_yolo_format(\"test\", test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd8wJ6Ko9nTq"
      },
      "source": [
        "# Object detection and bounding box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "eX4IECUC9qmZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "ed8be086-a037-475e-868c-adece5e4bc84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_dir = 'datasets/cars_license_plates/train/images'\n",
        "label_dir = 'datasets/cars_license_plates/train/labels'\n",
        "\n",
        "image_files = sorted(os.listdir(image_dir))\n",
        "first_image_file = image_files[0]\n",
        "\n",
        "# Construct paths for image and its label\n",
        "image_path = os.path.join(image_dir, first_image_file)\n",
        "label_path = os.path.join(label_dir, os.path.splitext(first_image_file)[0] + '.txt')\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert img BGR to OpenCV\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "with open(label_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "\n",
        "for line in lines:\n",
        "\n",
        "    class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "    img_height, img_width, _ = image.shape\n",
        "\n",
        "    # Convert YOLO format to bounding box format\n",
        "    x_center *= img_width\n",
        "    y_center *= img_height\n",
        "    width *= img_width\n",
        "    height *= img_height\n",
        "\n",
        "    x1 = int(x_center - width / 2)\n",
        "    y1 = int(y_center - height / 2)\n",
        "    x2 = int(x_center + width / 2)\n",
        "    y2 = int(y_center + height / 2)\n",
        "\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "obiQYXKJ9wfp"
      },
      "outputs": [],
      "source": [
        "datasets_yaml = '''\n",
        "path: cars_license_plates\n",
        "\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "\n",
        "# class names\n",
        "names: ['license_plate']\n",
        "'''\n",
        "\n",
        "# Write the content to the datasets.yaml file\n",
        "with open('dataset/datasets.yaml', 'w') as file:\n",
        "    file.write(datasets_yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJF5WplF92Mu"
      },
      "source": [
        "# Using YOLOv8 nano model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "cZhNRVKZ93Sq"
      },
      "outputs": [],
      "source": [
        "# using YOLOv8 nano\n",
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "bww2ZxEQ98pL"
      },
      "outputs": [],
      "source": [
        "os.environ['WANDB_MODE'] = 'offline'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_preprocessing(model, train_data):\n",
        "    def preprocessed_dataset(data):\n",
        "        for batch in data:\n",
        "            yield [preprocess_image(img) for img in batch]\n",
        "\n",
        "    results = model.train(data=preprocessed_dataset(train_data), epochs=100, imgsz=640)"
      ],
      "metadata": {
        "id": "jvGCFNwUHc7p"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "collapsed": true,
        "id": "eoahgfdr-Ai3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60720204-1f62-4a37-992b-0e69048ee399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.24 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=dataset/datasets.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=True, device=cuda, workers=8, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train15\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train15', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/cars_license_plates/train/labels... 345 images, 0 backgrounds, 0 corrupt: 100%|██████████| 345/345 [00:00<00:00, 855.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/cars_license_plates/train/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB RAM): 100%|██████████| 345/345 [00:01<00:00, 229.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/cars_license_plates/val/labels... 44 images, 0 backgrounds, 0 corrupt: 100%|██████████| 44/44 [00:00<00:00, 464.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/cars_license_plates/val/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100%|██████████| 44/44 [00:00<00:00, 236.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train15/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train15\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100     0.845G      2.094      3.176      1.488         19        320: 100%|██████████| 22/22 [00:04<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44     0.0037      0.818      0.072     0.0368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100     0.833G      1.777      1.946      1.254         19        320: 100%|██████████| 22/22 [00:02<00:00,  8.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44    0.00482      0.841     0.0274     0.0117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100     0.843G       1.77      1.694      1.306         23        320: 100%|██████████| 22/22 [00:05<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44          1      0.183      0.329      0.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100     0.835G      1.806      1.638      1.387         16        320: 100%|██████████| 22/22 [00:06<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.371      0.318      0.313       0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100     0.835G      1.745      1.568      1.323         20        320: 100%|██████████| 22/22 [00:05<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.222      0.273      0.176     0.0562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100     0.841G      1.803       1.56      1.345         19        320: 100%|██████████| 22/22 [00:04<00:00,  4.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.397      0.295      0.313       0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100     0.835G      1.772      1.509      1.333         18        320: 100%|██████████| 22/22 [00:02<00:00,  8.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.568      0.227       0.31      0.147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100     0.843G      1.803      1.496      1.309         19        320: 100%|██████████| 22/22 [00:02<00:00,  8.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.426      0.388      0.362      0.139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100     0.835G      1.689      1.369        1.3         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.573      0.659      0.617      0.273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100     0.841G      1.714      1.346      1.303         18        320: 100%|██████████| 22/22 [00:04<00:00,  4.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.677      0.432       0.51      0.231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100     0.835G      1.608       1.25       1.25         19        320: 100%|██████████| 22/22 [00:03<00:00,  5.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.821      0.312      0.446      0.204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100     0.841G      1.646      1.252      1.285         21        320: 100%|██████████| 22/22 [00:02<00:00,  8.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.573      0.641      0.594      0.265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100     0.835G      1.629      1.229      1.241         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.717      0.636      0.714      0.319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100     0.841G      1.642      1.247      1.271         16        320: 100%|██████████| 22/22 [00:03<00:00,  6.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.882      0.568      0.716      0.325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100     0.835G      1.567      1.167      1.203         19        320: 100%|██████████| 22/22 [00:04<00:00,  4.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.744      0.636      0.737      0.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100     0.841G      1.531      1.135      1.208         13        320: 100%|██████████| 22/22 [00:02<00:00,  8.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.83      0.778      0.856      0.416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100     0.835G      1.474      1.078      1.179         16        320: 100%|██████████| 22/22 [00:02<00:00,  8.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.757      0.659      0.704      0.326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100     0.841G       1.47      1.017      1.182         21        320: 100%|██████████| 22/22 [00:02<00:00,  7.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.762        0.5      0.662      0.349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100     0.835G      1.486      1.006      1.201         17        320: 100%|██████████| 22/22 [00:05<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.782      0.817      0.816       0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100     0.841G      1.495      1.008       1.19         24        320: 100%|██████████| 22/22 [00:03<00:00,  6.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.789       0.85      0.853        0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100     0.835G      1.418      0.991      1.155         21        320: 100%|██████████| 22/22 [00:03<00:00,  6.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.924      0.833      0.872      0.429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100     0.841G      1.441      1.024      1.174         14        320: 100%|██████████| 22/22 [00:03<00:00,  5.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.83      0.818      0.834      0.325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100     0.835G      1.448      1.011      1.164         14        320: 100%|██████████| 22/22 [00:04<00:00,  5.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.946      0.705      0.861      0.392\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100     0.841G      1.413      0.958      1.175         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.716      0.705      0.747      0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100     0.835G      1.409     0.9357      1.158         22        320: 100%|██████████| 22/22 [00:02<00:00,  8.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.798      0.539       0.68      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100     0.839G      1.423     0.9439      1.148         13        320: 100%|██████████| 22/22 [00:03<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.786      0.614      0.658      0.319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100     0.835G      1.371     0.9191      1.138         18        320: 100%|██████████| 22/22 [00:04<00:00,  4.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.736      0.571      0.666      0.334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100     0.841G      1.359     0.8818      1.107         18        320: 100%|██████████| 22/22 [00:02<00:00,  8.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.875      0.773      0.833      0.382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100     0.835G      1.349     0.9108      1.138         23        320: 100%|██████████| 22/22 [00:02<00:00,  8.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.88      0.832       0.85      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100     0.841G      1.361     0.8741      1.141         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.864      0.795      0.833      0.425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100     0.835G      1.336     0.8485      1.141         16        320: 100%|██████████| 22/22 [00:04<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.924      0.795      0.871      0.424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100     0.841G      1.345     0.8653      1.143         17        320: 100%|██████████| 22/22 [00:03<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.872      0.776      0.809      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100     0.835G      1.395     0.8769       1.16         19        320: 100%|██████████| 22/22 [00:02<00:00,  8.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.861      0.845      0.867      0.392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100     0.841G      1.282     0.8298      1.113         18        320: 100%|██████████| 22/22 [00:02<00:00,  7.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44        0.9      0.817      0.844      0.432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100     0.835G      1.296     0.8147      1.111         16        320: 100%|██████████| 22/22 [00:03<00:00,  5.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.861      0.636      0.757      0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100     0.841G        1.3     0.8511        1.1         19        320: 100%|██████████| 22/22 [00:03<00:00,  5.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.916      0.739      0.821      0.394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100     0.835G      1.331     0.8432      1.119         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.88      0.818      0.877      0.402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100     0.841G      1.291     0.8498      1.091         19        320: 100%|██████████| 22/22 [00:02<00:00,  7.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.826      0.865      0.856      0.407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100     0.835G      1.284      0.839      1.095         20        320: 100%|██████████| 22/22 [00:03<00:00,  6.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.857      0.682      0.808      0.396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100     0.841G      1.275     0.7772      1.083         19        320: 100%|██████████| 22/22 [00:04<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.902      0.773      0.876      0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100     0.835G      1.254     0.8201      1.088         17        320: 100%|██████████| 22/22 [00:02<00:00,  7.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.853      0.794      0.859      0.434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100     0.841G      1.192     0.7667      1.078         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.88      0.837      0.862      0.457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100     0.835G      1.233     0.7668      1.074         14        320: 100%|██████████| 22/22 [00:02<00:00,  8.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.958      0.795      0.895      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100     0.841G      1.273     0.7755       1.06         13        320: 100%|██████████| 22/22 [00:04<00:00,  5.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.964      0.795      0.877      0.444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100     0.835G      1.194     0.7406      1.043         16        320: 100%|██████████| 22/22 [00:03<00:00,  5.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.963      0.818        0.9      0.428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100     0.841G      1.184      0.745      1.068         18        320: 100%|██████████| 22/22 [00:02<00:00,  8.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.885      0.871      0.898      0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100     0.835G      1.231     0.7431      1.072         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.878      0.818      0.868      0.415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100     0.841G      1.195     0.7441      1.049         13        320: 100%|██████████| 22/22 [00:03<00:00,  6.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.931      0.818      0.862      0.419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100     0.835G      1.145     0.6951      1.034         12        320: 100%|██████████| 22/22 [00:04<00:00,  5.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.897      0.864      0.881      0.421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100     0.841G      1.196     0.7199       1.04         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.933      0.841      0.881      0.422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100     0.835G      1.154     0.7418      1.051         18        320: 100%|██████████| 22/22 [00:02<00:00,  8.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.831      0.818      0.866      0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100     0.841G      1.135     0.7159      1.042         17        320: 100%|██████████| 22/22 [00:02<00:00,  7.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.844      0.886      0.887      0.432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100     0.835G      1.171     0.7071      1.048         14        320: 100%|██████████| 22/22 [00:04<00:00,  5.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.926      0.853      0.895      0.442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100     0.841G      1.112     0.6821      1.034         23        320: 100%|██████████| 22/22 [00:02<00:00,  7.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.859      0.795      0.847      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100     0.833G       1.13     0.7207      1.042         10        320: 100%|██████████| 22/22 [00:02<00:00,  8.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.946      0.864      0.896      0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100     0.843G      1.136        0.7      1.024         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.915      0.795      0.849      0.407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100     0.835G      1.098     0.6826      1.022         14        320: 100%|██████████| 22/22 [00:04<00:00,  5.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.846      0.841      0.875      0.426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100     0.841G      1.139     0.7067      1.026         19        320: 100%|██████████| 22/22 [00:03<00:00,  5.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.806      0.864      0.858      0.432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100     0.835G      1.106      0.668      1.019         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.915      0.841      0.864      0.451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100     0.841G      1.093     0.6754      1.042         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.923      0.864      0.895      0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100     0.835G      1.134     0.6692      1.044         19        320: 100%|██████████| 22/22 [00:03<00:00,  6.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.902       0.84      0.862      0.433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100     0.841G      1.067     0.6641      1.018         20        320: 100%|██████████| 22/22 [00:04<00:00,  4.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.947      0.812      0.885       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100     0.833G      1.066     0.6544       1.03          9        320: 100%|██████████| 22/22 [00:02<00:00,  8.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.972      0.788      0.883      0.464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100     0.841G      1.079     0.6585      1.031         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.835      0.864      0.899      0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100     0.835G      1.079     0.6515      1.013         16        320: 100%|██████████| 22/22 [00:02<00:00,  8.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.929      0.773      0.889      0.453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100     0.841G      1.029     0.6319     0.9992         17        320: 100%|██████████| 22/22 [00:04<00:00,  4.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.82      0.864      0.877      0.442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100     0.835G       1.05      0.646      0.999         11        320: 100%|██████████| 22/22 [00:03<00:00,  5.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.829      0.818      0.873      0.441\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100     0.841G      1.044     0.6267      0.985         21        320: 100%|██████████| 22/22 [00:02<00:00,  8.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.921       0.79      0.871      0.438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100     0.835G      1.017     0.6231      1.005         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  8.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.788      0.846      0.843      0.414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100     0.841G      0.998     0.5965     0.9903         16        320: 100%|██████████| 22/22 [00:03<00:00,  6.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.867      0.864      0.875      0.422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100     0.835G      1.011     0.6184     0.9827         17        320: 100%|██████████| 22/22 [00:04<00:00,  4.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.924      0.841       0.91      0.428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100     0.841G     0.9662     0.5989     0.9858         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.95      0.862        0.9      0.447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100     0.835G      1.026     0.6215     0.9833         16        320: 100%|██████████| 22/22 [00:02<00:00,  8.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.944      0.841      0.885      0.448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100     0.841G      1.053     0.6283     0.9979         16        320: 100%|██████████| 22/22 [00:02<00:00,  8.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.949      0.886      0.887      0.447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100     0.835G     0.9974     0.6124     0.9991         11        320: 100%|██████████| 22/22 [00:04<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.927      0.862      0.901      0.448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100     0.841G     0.9575     0.6127     0.9865         16        320: 100%|██████████| 22/22 [00:03<00:00,  5.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.887      0.891      0.898      0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100     0.835G     0.9662     0.5766     0.9799         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.856      0.909      0.892      0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100     0.841G     0.9628     0.5936     0.9747         14        320: 100%|██████████| 22/22 [00:02<00:00,  8.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.861      0.909      0.896      0.455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100     0.835G     0.9958     0.5921      0.986         20        320: 100%|██████████| 22/22 [00:03<00:00,  6.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.882      0.886      0.898      0.481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100     0.841G     0.9735     0.5889     0.9864         20        320: 100%|██████████| 22/22 [00:04<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.947      0.818      0.885      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100     0.835G     0.9339     0.5745     0.9689         17        320: 100%|██████████| 22/22 [00:02<00:00,  8.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.901      0.818      0.885      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100     0.841G     0.9733     0.5856     0.9762         20        320: 100%|██████████| 22/22 [00:02<00:00,  8.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.864      0.866       0.91       0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100     0.835G     0.9174     0.5576     0.9647         19        320: 100%|██████████| 22/22 [00:03<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.948      0.831      0.881      0.475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100     0.841G     0.9069     0.5667     0.9543         20        320: 100%|██████████| 22/22 [00:04<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.906      0.878      0.892      0.461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100     0.835G     0.9449      0.581     0.9674         16        320: 100%|██████████| 22/22 [00:02<00:00,  8.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.896      0.886      0.903      0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100     0.841G     0.8962     0.5724     0.9637         15        320: 100%|██████████| 22/22 [00:02<00:00,  8.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.927      0.863      0.901      0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100     0.835G     0.9166     0.5755     0.9587         22        320: 100%|██████████| 22/22 [00:02<00:00,  7.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.95      0.862        0.9      0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100     0.841G     0.8958     0.5664     0.9648         14        320: 100%|██████████| 22/22 [00:04<00:00,  4.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.907      0.883      0.898      0.462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100     0.835G     0.8946       0.57     0.9617         21        320: 100%|██████████| 22/22 [00:03<00:00,  6.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.925      0.864      0.904      0.486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100     0.841G      0.905     0.5553      0.974         15        320: 100%|██████████| 22/22 [00:02<00:00,  7.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.922      0.864      0.909      0.455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100     0.833G      1.133     0.6586      1.088          9        320: 100%|██████████| 22/22 [00:03<00:00,  6.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.925      0.864      0.909      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100     0.841G      1.154     0.6367       1.09          9        320: 100%|██████████| 22/22 [00:04<00:00,  5.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.923      0.886        0.9      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100     0.833G      1.107     0.6042      1.081          9        320: 100%|██████████| 22/22 [00:06<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.951      0.886      0.908      0.479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100     0.841G      1.104     0.5825      1.069          9        320: 100%|██████████| 22/22 [00:02<00:00,  8.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 11.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.942      0.864      0.906      0.476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100     0.833G      1.101     0.5858      1.064          9        320: 100%|██████████| 22/22 [00:02<00:00,  7.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.92      0.864      0.892      0.486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100     0.841G      1.119     0.5876      1.055          9        320: 100%|██████████| 22/22 [00:04<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44        0.9      0.864      0.897      0.501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100     0.833G      1.084     0.5766      1.055          9        320: 100%|██████████| 22/22 [00:02<00:00,  8.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.92      0.864      0.901      0.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100     0.841G      1.055     0.5841      1.047          9        320: 100%|██████████| 22/22 [00:02<00:00,  8.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.921      0.864      0.903      0.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100     0.833G      1.001     0.5758       1.04          9        320: 100%|██████████| 22/22 [00:02<00:00,  8.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44       0.95      0.861      0.901      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100     0.841G      1.034     0.5515      1.036          9        320: 100%|██████████| 22/22 [00:03<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  6.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44      0.923      0.864      0.902      0.494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "100 epochs completed in 0.125 hours.\n",
            "Optimizer stripped from runs/detect/train15/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train15/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train15/weights/best.pt...\n",
            "Ultralytics 8.3.24 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         44         44        0.9      0.864      0.897      0.503\n",
            "Speed: 0.2ms preprocess, 1.5ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train15\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f9882a92200>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,\n",
              "            0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,     0.97297,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,\n",
              "              0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,       0.925,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,\n",
              "            0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,\n",
              "            0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.76471,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,\n",
              "            0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.57143,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,\n",
              "            0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.40594,     0.09631,    0.094893,    0.093477,    0.092061,    0.090644,    0.089228,    0.087812,    0.086395,    0.084979,    0.083563,    0.082146,     0.08073,\n",
              "           0.079314,    0.077898,    0.076481,    0.075065,    0.073649,    0.072232,    0.070816,      0.0694,    0.067983,    0.066567,    0.065151,    0.063734,    0.062318,    0.060902,    0.059485,    0.058069,    0.056653,    0.055236,     0.05382,    0.052404,    0.050987,    0.049571,    0.048155,\n",
              "           0.046739,    0.045322,    0.043906,     0.04249,    0.041073,    0.039657,    0.038241,    0.036824,    0.035408,    0.033992,    0.032575,    0.031159,    0.029743,    0.028326,     0.02691,    0.025494,    0.024077,    0.022661,    0.021245,    0.019828,    0.018412,    0.016996,     0.01558,\n",
              "           0.014163,    0.012747,    0.011331,   0.0099142,   0.0084979,   0.0070816,   0.0056653,    0.004249,   0.0028326,   0.0014163,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.17484,     0.17484,     0.25458,     0.29987,     0.35613,     0.41445,     0.44103,     0.47393,     0.48888,     0.50582,     0.53011,     0.56102,      0.5675,     0.57009,     0.58022,     0.58694,     0.59903,     0.61885,     0.62303,     0.62888,     0.63957,     0.64223,     0.64462,\n",
              "            0.65793,     0.66267,     0.66628,     0.66855,     0.67065,     0.67265,     0.67433,     0.67601,     0.67768,     0.68103,     0.68435,     0.68666,     0.68896,     0.69408,      0.6985,     0.70102,     0.69556,     0.69034,     0.69276,     0.69516,     0.69956,      0.7042,     0.70703,\n",
              "            0.71029,     0.71474,     0.71647,     0.71755,     0.71863,      0.7197,     0.72077,     0.72185,     0.72278,     0.72364,      0.7245,     0.72535,     0.72621,     0.72706,     0.72791,     0.72876,     0.73054,     0.73261,     0.73467,     0.73762,     0.74172,     0.74358,     0.74457,\n",
              "            0.74557,     0.74656,     0.74756,     0.74854,     0.74953,     0.75056,     0.75164,     0.75271,     0.75377,     0.75484,      0.7559,     0.75696,     0.76176,     0.76487,     0.76519,      0.7655,     0.76581,     0.76612,     0.76644,     0.76675,     0.76706,     0.76737,     0.76768,\n",
              "            0.76799,      0.7683,     0.76861,     0.76892,     0.76923,     0.76954,     0.76985,     0.77016,     0.77047,     0.77078,     0.77109,      0.7714,     0.77171,     0.77201,     0.77232,     0.77261,     0.77291,      0.7732,     0.77349,     0.77378,     0.77407,     0.77437,     0.77466,\n",
              "            0.77495,     0.77524,     0.77553,     0.77582,     0.77611,      0.7764,     0.77669,     0.77698,     0.77727,     0.77756,     0.77785,     0.77814,     0.77843,     0.77872,     0.77901,      0.7793,     0.77959,     0.77987,     0.78021,     0.78059,     0.78097,     0.78135,     0.78173,\n",
              "             0.7821,     0.78248,     0.78286,     0.78323,     0.78361,     0.78398,     0.78436,     0.78473,     0.78511,     0.78548,     0.78586,     0.78623,     0.78661,     0.78698,     0.78735,     0.78773,     0.78822,     0.78879,     0.78936,     0.78993,      0.7905,     0.79107,     0.79164,\n",
              "            0.79221,     0.79278,     0.79334,     0.79391,     0.79447,     0.79504,      0.7956,     0.79759,     0.80133,     0.80422,      0.8046,     0.80499,     0.80537,     0.80576,     0.80614,     0.80652,     0.80691,     0.80729,     0.80767,     0.80805,     0.80843,     0.80882,      0.8092,\n",
              "            0.80958,     0.80996,     0.81034,     0.81072,      0.8111,     0.81148,     0.81186,     0.81223,     0.81282,     0.81389,     0.81496,     0.81602,     0.81709,     0.81815,      0.8192,     0.82026,     0.81978,     0.81465,     0.80949,     0.80951,     0.81075,     0.81198,     0.81321,\n",
              "            0.81444,     0.81566,     0.81688,     0.81846,     0.82017,     0.82186,     0.82355,     0.82524,     0.82631,     0.82676,     0.82721,     0.82766,     0.82811,     0.82855,       0.829,     0.82945,      0.8299,     0.83034,     0.83079,     0.83123,     0.83168,     0.83212,     0.83257,\n",
              "            0.83301,     0.83345,      0.8339,     0.83434,     0.83478,     0.83524,     0.83583,     0.83642,     0.83701,      0.8376,     0.83819,     0.83877,     0.83936,     0.83995,     0.84053,     0.84112,      0.8417,     0.84228,     0.84286,     0.84344,     0.84402,     0.84452,      0.8448,\n",
              "            0.84508,     0.84536,     0.84563,     0.84591,     0.84619,     0.84647,     0.84675,     0.84702,      0.8473,     0.84758,     0.84785,     0.84813,     0.84841,     0.84868,     0.84896,     0.84924,     0.84951,     0.84979,     0.85006,     0.85034,     0.85061,     0.85089,     0.85116,\n",
              "            0.85144,     0.85171,     0.85199,     0.85226,     0.85253,     0.85281,     0.85308,     0.85335,     0.85363,      0.8539,     0.85466,     0.85548,      0.8563,     0.85711,     0.85793,     0.85874,     0.85955,     0.86036,     0.86117,     0.86197,     0.86278,     0.86358,     0.86457,\n",
              "            0.86557,     0.86657,     0.86757,     0.86856,     0.86955,     0.87054,     0.87153,     0.87252,      0.8735,     0.87371,     0.87388,     0.87404,      0.8742,     0.87436,     0.87452,     0.87468,     0.87484,       0.875,     0.87516,     0.87533,     0.87549,     0.87565,     0.87581,\n",
              "            0.87597,     0.87613,     0.87629,     0.87645,     0.87661,     0.87677,     0.87693,     0.87709,     0.87725,     0.87741,     0.87757,     0.87773,     0.87789,     0.87805,     0.87821,     0.87837,     0.87853,     0.87869,     0.87885,     0.87901,     0.87917,     0.87933,     0.87949,\n",
              "            0.87965,      0.8798,     0.87996,     0.88012,     0.88028,     0.88044,      0.8806,     0.88076,     0.88092,     0.88108,     0.88123,     0.88139,     0.88155,     0.88171,     0.88187,     0.88203,     0.88219,     0.88234,      0.8825,     0.88266,     0.88282,     0.88298,     0.88313,\n",
              "            0.88329,     0.88345,     0.88361,     0.88363,     0.88332,     0.88301,      0.8827,     0.88239,     0.88208,     0.88177,     0.88146,     0.88115,     0.88084,     0.88053,     0.88022,      0.8799,     0.87959,     0.87928,     0.87897,     0.87866,     0.87834,     0.87803,     0.87772,\n",
              "             0.8774,     0.87709,     0.87678,     0.87647,     0.87615,     0.87584,     0.87552,     0.87521,      0.8749,     0.87458,     0.87427,     0.87395,     0.87364,     0.87332,     0.87301,     0.87269,     0.87238,     0.87206,     0.87175,     0.87143,     0.87112,      0.8708,     0.87065,\n",
              "            0.87082,       0.871,     0.87117,     0.87135,     0.87153,      0.8717,     0.87188,     0.87205,     0.87223,     0.87241,     0.87258,     0.87276,     0.87293,     0.87311,     0.87328,     0.87346,     0.87363,     0.87381,     0.87398,     0.87416,     0.87433,     0.87451,     0.87468,\n",
              "            0.87486,     0.87503,     0.87521,     0.87538,     0.87555,     0.87573,      0.8759,     0.87608,     0.87625,     0.87643,      0.8766,     0.87677,     0.87695,     0.87712,     0.87729,     0.87747,     0.87764,     0.87781,     0.87799,     0.87816,     0.87833,     0.87851,     0.87868,\n",
              "            0.87885,     0.87902,      0.8792,     0.87937,     0.87954,     0.87972,     0.87989,     0.88006,     0.88023,      0.8804,     0.88058,     0.88075,     0.88092,     0.88085,     0.88073,     0.88061,     0.88048,     0.88036,     0.88024,     0.88012,     0.87999,     0.87987,     0.87975,\n",
              "            0.87962,      0.8795,     0.87938,     0.87926,     0.87913,     0.87901,     0.87889,     0.87876,     0.87864,     0.87852,     0.87839,     0.87827,     0.87815,     0.87802,      0.8779,     0.87778,     0.87765,     0.87753,     0.87741,     0.87728,     0.87716,     0.87704,     0.87691,\n",
              "            0.87679,     0.87667,     0.87654,     0.87642,      0.8763,     0.87617,     0.87605,     0.87593,      0.8758,     0.87568,     0.87556,     0.87543,     0.87531,     0.87518,     0.87506,     0.87494,     0.87481,     0.87469,     0.87456,     0.87444,     0.87432,     0.87419,     0.87407,\n",
              "            0.87395,     0.87382,      0.8737,     0.87357,     0.87345,     0.87332,      0.8732,     0.87308,     0.87295,     0.87283,      0.8727,     0.87258,     0.87246,     0.87233,     0.87221,     0.87208,     0.87196,     0.87183,     0.87171,     0.87158,     0.87146,     0.87134,     0.87121,\n",
              "            0.87109,     0.87096,     0.87084,     0.87071,     0.87059,     0.87046,     0.87034,     0.87021,     0.87009,     0.86997,     0.86984,     0.86972,     0.86959,     0.86947,     0.86934,     0.86922,     0.86909,     0.86897,     0.86884,     0.86872,     0.86859,     0.86847,     0.86834,\n",
              "            0.86822,     0.86809,     0.86797,     0.86784,     0.86772,     0.86759,     0.86748,     0.86772,     0.86796,      0.8682,     0.86844,     0.86869,     0.86893,     0.86917,     0.86941,     0.86965,     0.86989,     0.87013,     0.87037,     0.87061,     0.87085,     0.87109,     0.87133,\n",
              "            0.87157,      0.8718,     0.87204,     0.87228,     0.87252,     0.87276,       0.873,     0.87324,     0.87347,     0.87371,     0.87395,     0.87419,     0.87442,     0.87466,      0.8749,     0.87513,     0.87537,     0.87561,     0.87584,     0.87608,     0.87632,     0.87655,     0.87679,\n",
              "            0.87702,     0.87726,      0.8775,     0.87773,     0.87797,     0.87842,       0.879,     0.87958,     0.88015,     0.88073,      0.8813,     0.88187,     0.88245,     0.88302,     0.88359,     0.88416,     0.88472,     0.88529,     0.88586,     0.88642,     0.88699,     0.88755,     0.88812,\n",
              "            0.88868,     0.88862,     0.88818,     0.88775,     0.88732,     0.88688,     0.88645,     0.88601,     0.88558,     0.88514,     0.88471,     0.88427,     0.88383,      0.8834,     0.88296,     0.88252,     0.88209,     0.88165,     0.88121,     0.88077,     0.88033,     0.87989,     0.87945,\n",
              "            0.87901,     0.87857,     0.87813,     0.87769,     0.87725,     0.87681,     0.87636,     0.87592,     0.87548,     0.87504,     0.87323,      0.8713,     0.86936,     0.86742,     0.86546,     0.86351,     0.86154,     0.86029,     0.85951,     0.85873,     0.85795,     0.85717,     0.85638,\n",
              "             0.8556,     0.85481,     0.85403,     0.85324,     0.85245,     0.85166,     0.85087,     0.85008,     0.84928,     0.84849,     0.84769,      0.8469,     0.84595,     0.84291,     0.83985,     0.83678,     0.83369,     0.82921,     0.81871,     0.81401,     0.81153,     0.80905,     0.80656,\n",
              "            0.80406,     0.80155,     0.79957,     0.79843,      0.7973,     0.79616,     0.79502,     0.79388,     0.79273,     0.79159,     0.79044,     0.78929,     0.78814,     0.78698,     0.78583,     0.78467,     0.78111,     0.76973,     0.76444,     0.76095,     0.75744,     0.75391,     0.75037,\n",
              "            0.75219,     0.75462,     0.75702,      0.7594,     0.75936,     0.75696,     0.75456,     0.75214,     0.74972,     0.74729,     0.74484,      0.7417,     0.73552,     0.72928,     0.70562,     0.70462,     0.70362,     0.70261,      0.7016,      0.7006,     0.69959,     0.69858,     0.69756,\n",
              "            0.69655,     0.69553,     0.69452,      0.6935,     0.69248,     0.69146,     0.69043,     0.68941,     0.68838,     0.68735,     0.68617,     0.68449,     0.68281,     0.68112,     0.67943,     0.67774,     0.67604,     0.67433,     0.67263,     0.67091,      0.6692,     0.66748,     0.66529,\n",
              "            0.66269,     0.66008,     0.65746,     0.65483,     0.65219,     0.64954,     0.64688,     0.64421,     0.64153,     0.63884,     0.63614,     0.63342,      0.6307,     0.62796,     0.62522,     0.62297,     0.62075,     0.61854,     0.61631,     0.61407,     0.61183,     0.60959,     0.60733,\n",
              "            0.60507,     0.60259,     0.59909,     0.59556,     0.59202,     0.58845,     0.58488,     0.58128,      0.5318,     0.52722,     0.52261,     0.51797,     0.51331,     0.50861,     0.50532,     0.50206,     0.49879,      0.4955,      0.4922,     0.48888,     0.48555,     0.36943,     0.36378,\n",
              "            0.35809,     0.35236,     0.34659,     0.34078,     0.33566,     0.33068,     0.32567,     0.32063,     0.31556,     0.31046,     0.30154,     0.28799,     0.27415,     0.25663,     0.23982,     0.23724,     0.23465,     0.23205,     0.22945,     0.22684,     0.22422,     0.22159,     0.21895,\n",
              "            0.21631,     0.21366,       0.211,     0.20834,     0.20566,     0.20279,     0.19965,      0.1965,     0.19334,     0.19016,     0.18698,     0.18378,     0.18058,     0.17736,     0.17413,     0.17088,     0.16763,     0.10829,    0.085245,    0.078101,    0.070903,    0.063651,    0.056345,\n",
              "           0.048983,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.096471,    0.096471,     0.14743,     0.17869,     0.22013,     0.26649,     0.28888,     0.31778,     0.33137,     0.34712,     0.37043,     0.40133,     0.41251,     0.41524,     0.42608,     0.43337,     0.44668,     0.46908,     0.47391,     0.48071,     0.49332,     0.49648,     0.49935,\n",
              "            0.51551,     0.52136,     0.52584,     0.52867,      0.5313,     0.53381,     0.53593,     0.53805,     0.54017,     0.54444,     0.54871,     0.55168,     0.55465,     0.56132,     0.56712,     0.57103,     0.56808,     0.56532,     0.56857,     0.57181,     0.57779,     0.58414,     0.58805,\n",
              "            0.59258,      0.5988,     0.60123,     0.60275,     0.60427,     0.60579,     0.60732,     0.60884,     0.61017,     0.61139,     0.61262,     0.61384,     0.61507,     0.61629,     0.61752,     0.61874,     0.62131,     0.62431,     0.62731,     0.63162,     0.63766,     0.64041,     0.64189,\n",
              "            0.64337,     0.64486,     0.64634,     0.64782,      0.6493,     0.65085,     0.65246,     0.65408,     0.65569,      0.6573,     0.65892,     0.66053,     0.66787,     0.67267,     0.67316,     0.67364,     0.67413,     0.67461,     0.67509,     0.67558,     0.67606,     0.67654,     0.67703,\n",
              "            0.67751,     0.67799,     0.67848,     0.67896,     0.67945,     0.67993,     0.68041,      0.6809,     0.68138,     0.68186,     0.68235,     0.68283,     0.68332,      0.6838,     0.68428,     0.68474,      0.6852,     0.68566,     0.68612,     0.68658,     0.68704,      0.6875,     0.68796,\n",
              "            0.68842,     0.68887,     0.68933,     0.68979,     0.69025,     0.69071,     0.69117,     0.69163,     0.69209,     0.69255,     0.69301,     0.69347,     0.69393,     0.69439,     0.69485,     0.69531,     0.69577,     0.69623,     0.69677,     0.69737,     0.69798,     0.69858,     0.69918,\n",
              "            0.69979,     0.70039,     0.70099,      0.7016,      0.7022,     0.70281,     0.70341,     0.70401,     0.70462,     0.70522,     0.70582,     0.70643,     0.70703,     0.70764,     0.70824,     0.70884,     0.70964,     0.71057,     0.71149,     0.71242,     0.71335,     0.71428,     0.71521,\n",
              "            0.71614,     0.71706,     0.71799,     0.71892,     0.71985,     0.72078,     0.72171,     0.72497,     0.73118,     0.73601,     0.73665,      0.7373,     0.73794,     0.73859,     0.73923,     0.73988,     0.74052,     0.74117,     0.74181,     0.74246,      0.7431,     0.74375,     0.74439,\n",
              "            0.74503,     0.74568,     0.74632,     0.74697,     0.74761,     0.74826,      0.7489,     0.74955,     0.75054,     0.75237,      0.7542,     0.75602,     0.75785,     0.75968,     0.76151,     0.76333,     0.76423,      0.7623,     0.76037,     0.76178,     0.76397,     0.76616,     0.76835,\n",
              "            0.77055,     0.77274,     0.77493,     0.77778,     0.78086,     0.78394,     0.78702,      0.7901,     0.79207,      0.7929,     0.79373,     0.79456,     0.79538,     0.79621,     0.79704,     0.79786,     0.79869,     0.79952,     0.80035,     0.80117,       0.802,     0.80283,     0.80365,\n",
              "            0.80448,     0.80531,     0.80613,     0.80696,     0.80779,     0.80865,     0.80976,     0.81087,     0.81198,     0.81309,      0.8142,      0.8153,     0.81641,     0.81752,     0.81863,     0.81974,     0.82085,     0.82196,     0.82307,     0.82417,     0.82528,     0.82623,     0.82677,\n",
              "             0.8273,     0.82783,     0.82837,      0.8289,     0.82944,     0.82997,      0.8305,     0.83104,     0.83157,     0.83211,     0.83264,     0.83317,     0.83371,     0.83424,     0.83477,     0.83531,     0.83584,     0.83638,     0.83691,     0.83744,     0.83798,     0.83851,     0.83904,\n",
              "            0.83958,     0.84011,     0.84065,     0.84118,     0.84171,     0.84225,     0.84278,     0.84332,     0.84385,     0.84438,     0.84587,     0.84747,     0.84908,     0.85068,     0.85229,      0.8539,      0.8555,     0.85711,     0.85871,     0.86032,     0.86192,     0.86353,     0.86551,\n",
              "            0.86752,     0.86953,     0.87154,     0.87355,     0.87556,     0.87756,     0.87957,     0.88158,     0.88359,     0.88403,     0.88436,     0.88469,     0.88502,     0.88535,     0.88568,     0.88601,     0.88634,     0.88667,       0.887,     0.88734,     0.88767,       0.888,     0.88833,\n",
              "            0.88866,     0.88899,     0.88932,     0.88965,     0.88998,     0.89031,     0.89064,     0.89097,      0.8913,     0.89163,     0.89196,     0.89229,     0.89262,     0.89295,     0.89328,     0.89362,     0.89395,     0.89428,     0.89461,     0.89494,     0.89527,      0.8956,     0.89593,\n",
              "            0.89626,     0.89659,     0.89692,     0.89725,     0.89758,     0.89791,     0.89824,     0.89857,      0.8989,     0.89923,     0.89956,      0.8999,     0.90023,     0.90056,     0.90089,     0.90122,     0.90155,     0.90188,     0.90221,     0.90254,     0.90287,      0.9032,     0.90353,\n",
              "            0.90386,     0.90419,     0.90452,     0.90475,     0.90469,     0.90464,     0.90458,     0.90453,     0.90447,     0.90441,     0.90436,      0.9043,     0.90425,     0.90419,     0.90414,     0.90408,     0.90403,     0.90397,     0.90392,     0.90386,     0.90381,     0.90375,     0.90369,\n",
              "            0.90364,     0.90358,     0.90353,     0.90347,     0.90342,     0.90336,     0.90331,     0.90325,      0.9032,     0.90314,     0.90309,     0.90303,     0.90297,     0.90292,     0.90286,     0.90281,     0.90275,      0.9027,     0.90264,     0.90259,     0.90253,     0.90248,     0.90256,\n",
              "            0.90294,     0.90332,      0.9037,     0.90408,     0.90446,     0.90484,     0.90522,      0.9056,     0.90598,     0.90635,     0.90673,     0.90711,     0.90749,     0.90787,     0.90825,     0.90863,     0.90901,     0.90939,     0.90977,     0.91015,     0.91052,      0.9109,     0.91128,\n",
              "            0.91166,     0.91204,     0.91242,      0.9128,     0.91318,     0.91356,     0.91394,     0.91432,     0.91469,     0.91507,     0.91545,     0.91583,     0.91621,     0.91659,     0.91697,     0.91735,     0.91773,     0.91811,     0.91849,     0.91886,     0.91924,     0.91962,        0.92,\n",
              "            0.92038,     0.92076,     0.92114,     0.92152,      0.9219,     0.92228,     0.92266,     0.92303,     0.92341,     0.92379,     0.92417,     0.92455,     0.92493,     0.92499,     0.92497,     0.92495,     0.92493,     0.92491,      0.9249,     0.92488,     0.92486,     0.92484,     0.92483,\n",
              "            0.92481,     0.92479,     0.92477,     0.92476,     0.92474,     0.92472,      0.9247,     0.92469,     0.92467,     0.92465,     0.92463,     0.92461,      0.9246,     0.92458,     0.92456,     0.92454,     0.92453,     0.92451,     0.92449,     0.92447,     0.92446,     0.92444,     0.92442,\n",
              "             0.9244,     0.92438,     0.92437,     0.92435,     0.92433,     0.92431,      0.9243,     0.92428,     0.92426,     0.92424,     0.92423,     0.92421,     0.92419,     0.92417,     0.92415,     0.92414,     0.92412,      0.9241,     0.92408,     0.92407,     0.92405,     0.92403,     0.92401,\n",
              "              0.924,     0.92398,     0.92396,     0.92394,     0.92392,     0.92391,     0.92389,     0.92387,     0.92385,     0.92384,     0.92382,      0.9238,     0.92378,     0.92377,     0.92375,     0.92373,     0.92371,      0.9237,     0.92368,     0.92366,     0.92364,     0.92362,     0.92361,\n",
              "            0.92359,     0.92357,     0.92355,     0.92354,     0.92352,      0.9235,     0.92348,     0.92347,     0.92345,     0.92343,     0.92341,     0.92339,     0.92338,     0.92336,     0.92334,     0.92332,     0.92331,     0.92329,     0.92327,     0.92325,     0.92324,     0.92322,      0.9232,\n",
              "            0.92318,     0.92316,     0.92315,     0.92313,     0.92311,     0.92309,      0.9231,     0.92365,     0.92419,     0.92474,     0.92529,     0.92583,     0.92638,     0.92693,     0.92748,     0.92802,     0.92857,     0.92912,     0.92966,     0.93021,     0.93076,     0.93131,     0.93185,\n",
              "             0.9324,     0.93295,      0.9335,     0.93404,     0.93459,     0.93514,     0.93568,     0.93623,     0.93678,     0.93733,     0.93787,     0.93842,     0.93897,     0.93952,     0.94006,     0.94061,     0.94116,      0.9417,     0.94225,      0.9428,     0.94335,     0.94389,     0.94444,\n",
              "            0.94499,     0.94553,     0.94608,     0.94663,     0.94718,     0.94824,     0.94959,     0.95093,     0.95228,     0.95363,     0.95497,     0.95632,     0.95766,     0.95901,     0.96036,      0.9617,     0.96305,     0.96439,     0.96574,     0.96709,     0.96843,     0.96978,     0.97112,\n",
              "            0.97247,     0.97296,     0.97293,     0.97291,     0.97289,     0.97286,     0.97284,     0.97282,     0.97279,     0.97277,     0.97275,     0.97272,      0.9727,     0.97267,     0.97265,     0.97263,      0.9726,     0.97258,     0.97256,     0.97253,     0.97251,     0.97248,     0.97246,\n",
              "            0.97244,     0.97241,     0.97239,     0.97237,     0.97234,     0.97232,      0.9723,     0.97227,     0.97225,     0.97222,     0.97212,     0.97201,     0.97191,      0.9718,     0.97169,     0.97158,     0.97147,      0.9714,     0.97136,     0.97131,     0.97127,     0.97122,     0.97117,\n",
              "            0.97113,     0.97108,     0.97104,     0.97099,     0.97095,      0.9709,     0.97086,     0.97081,     0.97077,     0.97072,     0.97068,     0.97063,     0.97058,     0.97039,     0.97021,     0.97003,     0.96985,     0.96958,     0.96893,     0.96863,     0.96848,     0.96832,     0.96816,\n",
              "              0.968,     0.96784,     0.96771,     0.96764,     0.96756,     0.96748,     0.96741,     0.96733,     0.96726,     0.96718,      0.9671,     0.96703,     0.96695,     0.96688,      0.9668,     0.96672,     0.96648,     0.96569,     0.96532,     0.96507,     0.96482,     0.96456,     0.96431,\n",
              "            0.97157,     0.97971,     0.98784,     0.99598,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,\n",
              "            0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90763,     0.89683,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,\n",
              "            0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,\n",
              "            0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,\n",
              "            0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,\n",
              "            0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,\n",
              "            0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,\n",
              "            0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,\n",
              "            0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88636,     0.88405,     0.87473,     0.86541,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n",
              "            0.86364,     0.86364,     0.86364,     0.86349,     0.86294,      0.8624,     0.86186,     0.86132,     0.86078,     0.86024,     0.85969,     0.85915,     0.85861,     0.85807,     0.85753,     0.85698,     0.85644,      0.8559,     0.85536,     0.85482,     0.85428,     0.85373,     0.85319,\n",
              "            0.85265,     0.85211,     0.85157,     0.85103,     0.85048,     0.84994,      0.8494,     0.84886,     0.84832,     0.84777,     0.84723,     0.84669,     0.84615,     0.84561,     0.84507,     0.84452,     0.84398,     0.84344,      0.8429,     0.84236,     0.84182,     0.84127,     0.84091,\n",
              "            0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,\n",
              "            0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,\n",
              "            0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84091,     0.84074,     0.84053,     0.84032,     0.84011,      0.8399,     0.83969,     0.83948,     0.83928,     0.83907,     0.83886,\n",
              "            0.83865,     0.83844,     0.83823,     0.83802,     0.83781,      0.8376,      0.8374,     0.83719,     0.83698,     0.83677,     0.83656,     0.83635,     0.83614,     0.83593,     0.83572,     0.83552,     0.83531,      0.8351,     0.83489,     0.83468,     0.83447,     0.83426,     0.83405,\n",
              "            0.83384,     0.83363,     0.83343,     0.83322,     0.83301,      0.8328,     0.83259,     0.83238,     0.83217,     0.83196,     0.83175,     0.83155,     0.83134,     0.83113,     0.83092,     0.83071,      0.8305,     0.83029,     0.83008,     0.82987,     0.82967,     0.82946,     0.82925,\n",
              "            0.82904,     0.82883,     0.82862,     0.82841,      0.8282,     0.82799,     0.82778,     0.82758,     0.82737,     0.82716,     0.82695,     0.82674,     0.82653,     0.82632,     0.82611,      0.8259,      0.8257,     0.82549,     0.82528,     0.82507,     0.82486,     0.82465,     0.82444,\n",
              "            0.82423,     0.82402,     0.82381,     0.82361,      0.8234,     0.82319,     0.82298,     0.82277,     0.82256,     0.82235,     0.82214,     0.82193,     0.82173,     0.82152,     0.82131,      0.8211,     0.82089,     0.82068,     0.82047,     0.82026,     0.82005,     0.81985,     0.81964,\n",
              "            0.81943,     0.81922,     0.81901,      0.8188,     0.81859,     0.81838,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,\n",
              "            0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,\n",
              "            0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,\n",
              "            0.81818,     0.81773,     0.81702,      0.8163,     0.81558,     0.81487,     0.81415,     0.81343,     0.81272,       0.812,     0.81128,     0.81057,     0.80985,     0.80913,     0.80842,      0.8077,     0.80698,     0.80626,     0.80555,     0.80483,     0.80411,      0.8034,     0.80268,\n",
              "            0.80196,     0.80125,     0.80053,     0.79981,      0.7991,     0.79838,     0.79766,     0.79695,     0.79623,     0.79551,      0.7926,     0.78949,     0.78639,     0.78328,     0.78018,     0.77707,     0.77396,     0.77199,     0.77076,     0.76954,     0.76831,     0.76708,     0.76586,\n",
              "            0.76463,     0.76341,     0.76218,     0.76095,     0.75973,      0.7585,     0.75728,     0.75605,     0.75482,      0.7536,     0.75237,     0.75115,     0.74969,     0.74503,     0.74037,     0.73572,     0.73106,     0.72435,     0.70882,     0.70195,     0.69836,     0.69478,      0.6912,\n",
              "            0.68761,     0.68403,      0.6812,      0.6796,     0.67799,     0.67638,     0.67478,     0.67317,     0.67156,     0.66996,     0.66835,     0.66674,     0.66514,     0.66353,     0.66192,     0.66032,     0.65541,     0.63987,     0.63276,      0.6281,     0.62344,     0.61878,     0.61412,\n",
              "            0.61364,     0.61364,     0.61364,     0.61364,     0.61207,     0.60896,     0.60585,     0.60275,     0.59964,     0.59653,     0.59343,     0.58944,     0.58168,     0.57391,     0.54514,     0.54395,     0.54275,     0.54156,     0.54036,     0.53917,     0.53797,     0.53678,     0.53558,\n",
              "            0.53439,     0.53319,       0.532,     0.53081,     0.52961,     0.52842,     0.52722,     0.52603,     0.52483,     0.52364,     0.52226,     0.52032,     0.51838,     0.51644,      0.5145,     0.51256,     0.51062,     0.50868,     0.50673,     0.50479,     0.50285,     0.50091,     0.49845,\n",
              "            0.49554,     0.49263,     0.48972,      0.4868,     0.48389,     0.48098,     0.47807,     0.47516,     0.47224,     0.46933,     0.46642,     0.46351,      0.4606,     0.45768,     0.45477,      0.4524,     0.45007,     0.44774,     0.44541,     0.44308,     0.44075,     0.43842,     0.43609,\n",
              "            0.43376,     0.43122,     0.42764,     0.42406,     0.42047,     0.41689,      0.4133,     0.40972,     0.36221,     0.35797,     0.35374,      0.3495,     0.34527,     0.34103,     0.33808,     0.33517,     0.33226,     0.32934,     0.32643,     0.32352,     0.32061,     0.22657,     0.22233,\n",
              "             0.2181,     0.21386,     0.20962,     0.20539,     0.20168,     0.19809,     0.19451,     0.19092,     0.18734,     0.18376,     0.17754,     0.16822,     0.15885,      0.1472,     0.13625,     0.13458,     0.13292,     0.13126,     0.12959,     0.12793,     0.12626,      0.1246,     0.12294,\n",
              "            0.12127,     0.11961,     0.11794,     0.11628,     0.11462,     0.11284,      0.1109,     0.10896,     0.10701,     0.10507,     0.10313,     0.10119,    0.099249,    0.097308,    0.095366,    0.093425,    0.091484,    0.057247,     0.04452,    0.040637,    0.036755,    0.032872,    0.028989,\n",
              "           0.025107,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.5422894253953132\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.50284])\n",
              "names: {0: 'license_plate'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.8998955252482236, 'metrics/recall(B)': 0.8636363636363636, 'metrics/mAP50(B)': 0.8973120337048922, 'metrics/mAP50-95(B)': 0.5028424689164711, 'fitness': 0.5422894253953132}\n",
              "save_dir: PosixPath('runs/detect/train15')\n",
              "speed: {'preprocess': 0.20584735003384677, 'inference': 1.501343467018821, 'loss': 0.000579790635542436, 'postprocess': 1.2852820483121004}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "model.train(\n",
        "    data=f'{dataset_path}/datasets.yaml',\n",
        "    epochs=100,\n",
        "    batch=16,\n",
        "    device='cuda',\n",
        "    imgsz=320,  # Image size (width and height) for training\n",
        "    cache=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "nu49bltDAFn9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "0d1654fb-064c-4fd4-d364-aa7c23098d62"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Find recent training log dir\n",
        "log_dir = max(glob('runs/detect/train*'), key=extract_number_from_str)\n",
        "\n",
        "results = pd.read_csv(os.path.join(log_dir, 'results.csv'))\n",
        "results.columns = results.columns.str.strip()\n",
        "\n",
        "epochs = results.index + 1\n",
        "mAP_0_5 = results['metrics/mAP50(B)']\n",
        "mAP_0_5_0_95 = results['metrics/mAP50-95(B)']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, mAP_0_5, label='mAP@0.5')\n",
        "plt.plot(epochs, mAP_0_5_0_95, label='mAP@0.5:0.95')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"Calculate Intersection over Union (IoU) between two boxes\"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    union = box1_area + box2_area - intersection\n",
        "\n",
        "    return intersection / union if union > 0 else 0\n",
        "\n",
        "def calculate_metrics(predictions, ground_truth, iou_thresholds=[0.5]):\n",
        "    \"\"\"\n",
        "    Calculate precision, recall, mAP, and F1 score for object detection\n",
        "\n",
        "    Args:\n",
        "        predictions: List of dictionaries containing predicted boxes and scores\n",
        "        ground_truth: List of dictionaries containing ground truth boxes\n",
        "        iou_thresholds: List of IoU thresholds for evaluation\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing calculated metrics\n",
        "    \"\"\"\n",
        "    metrics = defaultdict(dict)\n",
        "\n",
        "    for iou_threshold in iou_thresholds:\n",
        "        true_positives = []\n",
        "        false_positives = []\n",
        "        scores = []\n",
        "        n_ground_truth = 0\n",
        "\n",
        "        # Process each image\n",
        "        for img_id in ground_truth:\n",
        "            gt_boxes = ground_truth[img_id]\n",
        "            pred_boxes = predictions.get(img_id, [])\n",
        "            n_ground_truth += len(gt_boxes)\n",
        "\n",
        "            # Mark ground truth boxes as not detected yet\n",
        "            gt_matched = [False] * len(gt_boxes)\n",
        "\n",
        "            # Sort predictions by confidence score\n",
        "            pred_boxes = sorted(pred_boxes, key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "            for pred in pred_boxes:\n",
        "                scores.append(pred['confidence'])\n",
        "                max_iou = 0\n",
        "                max_idx = -1\n",
        "\n",
        "                # Find the best matching ground truth box\n",
        "                for idx, gt_box in enumerate(gt_boxes):\n",
        "                    if not gt_matched[idx]:\n",
        "                        iou = calculate_iou(pred['bbox'], gt_box)\n",
        "                        if iou > max_iou:\n",
        "                            max_iou = iou\n",
        "                            max_idx = idx\n",
        "\n",
        "                if max_iou >= iou_threshold and max_idx >= 0:\n",
        "                    true_positives.append(1)\n",
        "                    false_positives.append(0)\n",
        "                    gt_matched[max_idx] = True\n",
        "                else:\n",
        "                    true_positives.append(0)\n",
        "                    false_positives.append(1)\n",
        "\n",
        "        # Calculate cumulative precision and recall\n",
        "        cumsum_tp = np.cumsum(true_positives)\n",
        "        cumsum_fp = np.cumsum(false_positives)\n",
        "        precision = cumsum_tp / (cumsum_tp + cumsum_fp)\n",
        "        recall = cumsum_tp / n_ground_truth if n_ground_truth > 0 else np.zeros_like(cumsum_tp)\n",
        "\n",
        "        # Calculate AP using 11-point interpolation\n",
        "        ap = 0\n",
        "        for t in np.arange(0, 1.1, 0.1):\n",
        "            if np.sum(recall >= t) == 0:\n",
        "                p = 0\n",
        "            else:\n",
        "                p = np.max(precision[recall >= t])\n",
        "            ap += p / 11\n",
        "\n",
        "        # Calculate F1 score\n",
        "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
        "        max_f1 = np.max(f1) if len(f1) > 0 else 0\n",
        "\n",
        "        metrics[f'mAP@{iou_threshold}'] = ap\n",
        "        metrics[f'precision@{iou_threshold}'] = np.mean(precision)\n",
        "        metrics[f'recall@{iou_threshold}'] = np.mean(recall)\n",
        "        metrics[f'f1@{iou_threshold}'] = max_f1\n",
        "\n",
        "    # Calculate mAP@0.5:0.95\n",
        "    if len(iou_thresholds) > 1:\n",
        "        metrics['mAP@0.5:0.95'] = np.mean([metrics[f'mAP@{t}'] for t in iou_thresholds])\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_model(model, test_df, output_dir='predictions'):\n",
        "    \"\"\"\n",
        "    Evaluate model performance on test dataset\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        test_df: DataFrame containing test image paths\n",
        "        output_dir: Directory to save results\n",
        "    \"\"\"\n",
        "    # Get predictions\n",
        "    predictions = {}\n",
        "    ground_truth = {}\n",
        "\n",
        "    # Process test images\n",
        "    for idx, row in test_df.iterrows():\n",
        "        img_path = row['img_path']\n",
        "        img_name = os.path.basename(img_path)\n",
        "\n",
        "        # Get model predictions\n",
        "        results = model.predict(img_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Store predictions\n",
        "        predictions[img_name] = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                confidence = float(box.conf[0])\n",
        "                predictions[img_name].append({\n",
        "                    'bbox': [x1, y1, x2, y2],\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "        # Store ground truth\n",
        "        ground_truth[img_name] = [[row['xmin'], row['ymin'], row['xmax'], row['ymax']]]\n",
        "\n",
        "    # Calculate metrics for different IoU thresholds\n",
        "    iou_thresholds = np.linspace(0.5, 0.95, 10)\n",
        "    metrics = calculate_metrics(predictions, ground_truth, iou_thresholds)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nEvaluation Metrics:\")\n",
        "    print(f\"mAP@0.5: {metrics['mAP@0.5']:.4f}\")\n",
        "    print(f\"mAP@0.5:0.95: {metrics['mAP@0.5:0.95']:.4f}\")\n",
        "    print(f\"Precision@0.5: {metrics['precision@0.5']:.4f}\")\n",
        "    print(f\"Recall@0.5: {metrics['recall@0.5']:.4f}\")\n",
        "    print(f\"F1@0.5: {metrics['f1@0.5']:.4f}\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "111ANM-5KgI_"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-jaSTGaLcSc",
        "outputId": "83777058-8b64-4ddf-e6e5-540fdb303b05"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars425.png: 160x320 1 license_plate, 53.9ms\n",
            "Speed: 1.5ms preprocess, 53.9ms inference, 1.2ms postprocess per image at shape (1, 3, 160, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars75.png: 224x320 1 license_plate, 50.5ms\n",
            "Speed: 1.0ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars181.png: 320x192 1 license_plate, 44.9ms\n",
            "Speed: 0.9ms preprocess, 44.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 192)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars30.png: 192x320 2 license_plates, 43.6ms\n",
            "Speed: 0.9ms preprocess, 43.6ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars364.png: 224x320 1 license_plate, 51.8ms\n",
            "Speed: 1.0ms preprocess, 51.8ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars408.png: 224x320 1 license_plate, 52.9ms\n",
            "Speed: 0.9ms preprocess, 52.9ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars253.png: 192x320 1 license_plate, 46.1ms\n",
            "Speed: 0.8ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars155.png: 224x320 (no detections), 48.8ms\n",
            "Speed: 1.0ms preprocess, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars168.png: 192x320 1 license_plate, 77.1ms\n",
            "Speed: 0.9ms preprocess, 77.1ms inference, 2.9ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars415.png: 256x320 1 license_plate, 45.0ms\n",
            "Speed: 1.1ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars152.png: 224x320 1 license_plate, 34.2ms\n",
            "Speed: 0.7ms preprocess, 34.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars70.png: 192x320 (no detections), 27.0ms\n",
            "Speed: 0.8ms preprocess, 27.0ms inference, 0.4ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars203.png: 224x320 1 license_plate, 30.4ms\n",
            "Speed: 0.9ms preprocess, 30.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars335.png: 320x320 2 license_plates, 38.9ms\n",
            "Speed: 0.9ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars39.png: 256x320 1 license_plate, 33.6ms\n",
            "Speed: 0.9ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars395.png: 256x320 1 license_plate, 35.1ms\n",
            "Speed: 0.8ms preprocess, 35.1ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars274.png: 256x320 1 license_plate, 33.3ms\n",
            "Speed: 0.8ms preprocess, 33.3ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars72.png: 288x320 2 license_plates, 47.7ms\n",
            "Speed: 0.9ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars9.png: 256x320 1 license_plate, 32.9ms\n",
            "Speed: 1.0ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars281.png: 224x320 1 license_plate, 31.6ms\n",
            "Speed: 1.0ms preprocess, 31.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars287.png: 288x320 2 license_plates, 38.4ms\n",
            "Speed: 1.2ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 288, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars362.png: 256x320 (no detections), 35.2ms\n",
            "Speed: 1.5ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars353.png: 224x320 1 license_plate, 32.0ms\n",
            "Speed: 0.8ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars55.png: 256x320 2 license_plates, 37.6ms\n",
            "Speed: 1.5ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars289.png: 256x320 1 license_plate, 34.5ms\n",
            "Speed: 1.5ms preprocess, 34.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars198.png: 256x320 1 license_plate, 36.0ms\n",
            "Speed: 1.0ms preprocess, 36.0ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars148.png: 192x320 (no detections), 30.1ms\n",
            "Speed: 0.9ms preprocess, 30.1ms inference, 0.4ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars392.png: 224x320 1 license_plate, 32.7ms\n",
            "Speed: 1.0ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars341.png: 224x320 1 license_plate, 32.2ms\n",
            "Speed: 1.0ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars268.png: 256x320 1 license_plate, 39.9ms\n",
            "Speed: 0.8ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars126.png: 256x320 1 license_plate, 45.2ms\n",
            "Speed: 2.5ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars400.png: 224x320 1 license_plate, 44.2ms\n",
            "Speed: 1.0ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars305.png: 192x320 1 license_plate, 36.2ms\n",
            "Speed: 1.1ms preprocess, 36.2ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars93.png: 224x320 (no detections), 40.8ms\n",
            "Speed: 0.9ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars428.png: 192x320 1 license_plate, 37.6ms\n",
            "Speed: 0.8ms preprocess, 37.6ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars77.png: 224x320 1 license_plate, 42.2ms\n",
            "Speed: 1.1ms preprocess, 42.2ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars298.png: 224x320 (no detections), 39.2ms\n",
            "Speed: 1.0ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars140.png: 224x320 1 license_plate, 33.3ms\n",
            "Speed: 0.7ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars323.png: 192x320 1 license_plate, 30.4ms\n",
            "Speed: 1.8ms preprocess, 30.4ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars429.png: 320x256 1 license_plate, 52.3ms\n",
            "Speed: 1.2ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 256)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars225.png: 224x320 1 license_plate, 32.1ms\n",
            "Speed: 1.2ms preprocess, 32.1ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars154.png: 320x256 1 license_plate, 37.0ms\n",
            "Speed: 1.1ms preprocess, 37.0ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 256)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars78.png: 256x320 1 license_plate, 34.6ms\n",
            "Speed: 0.8ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n",
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars73.png: 192x320 1 license_plate, 28.4ms\n",
            "Speed: 0.9ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n",
            "\n",
            "Evaluation Metrics:\n",
            "mAP@0.5: 0.6089\n",
            "mAP@0.5:0.95: 0.3519\n",
            "Precision@0.5: 0.7363\n",
            "Recall@0.5: 0.3805\n",
            "F1@0.5: 0.8046\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(dict,\n",
              "            {'mAP@0.5': 0.6088794926004228,\n",
              "             'precision@0.5': 0.7362870874590688,\n",
              "             'recall@0.5': 0.38054968287526436,\n",
              "             'f1@0.5': 0.8045972012157948,\n",
              "             'mAP@0.55': 0.5792811839323467,\n",
              "             'precision@0.55': 0.6838982413629882,\n",
              "             'recall@0.55': 0.3525369978858351,\n",
              "             'f1@0.55': 0.7586201897215609,\n",
              "             'mAP@0.6': 0.5792811839323467,\n",
              "             'precision@0.6': 0.6838982413629882,\n",
              "             'recall@0.6': 0.3525369978858351,\n",
              "             'f1@0.6': 0.7586201897215609,\n",
              "             'mAP@0.65': 0.5644820295983086,\n",
              "             'precision@0.65': 0.679818254762821,\n",
              "             'recall@0.65': 0.3488372093023256,\n",
              "             'f1@0.65': 0.7356316839744447,\n",
              "             'mAP@0.7': 0.46753246753246747,\n",
              "             'precision@0.7': 0.6129715697323199,\n",
              "             'recall@0.7': 0.3134249471458774,\n",
              "             'f1@0.7': 0.6744181049219495,\n",
              "             'mAP@0.75': 0.35064935064935066,\n",
              "             'precision@0.75': 0.4774841026066365,\n",
              "             'recall@0.75': 0.24947145877378438,\n",
              "             'f1@0.75': 0.5581390351545847,\n",
              "             'mAP@0.8': 0.2600756488848311,\n",
              "             'precision@0.8': 0.43258004396089705,\n",
              "             'recall@0.8': 0.2167019027484144,\n",
              "             'f1@0.8': 0.447058324152807,\n",
              "             'mAP@0.85': 0.08647450110864745,\n",
              "             'precision@0.85': 0.2201597852504392,\n",
              "             'recall@0.85': 0.13266384778012688,\n",
              "             'f1@0.85': 0.3058818535648291,\n",
              "             'mAP@0.8999999999999999': 0.022172949002217293,\n",
              "             'precision@0.8999999999999999': 0.0668693810793812,\n",
              "             'recall@0.8999999999999999': 0.04281183932346722,\n",
              "             'f1@0.8999999999999999': 0.11764655944848647,\n",
              "             'mAP@0.95': 0.0,\n",
              "             'precision@0.95': 0.0,\n",
              "             'recall@0.95': 0.0,\n",
              "             'f1@0.95': 0.0,\n",
              "             'mAP@0.5:0.95': 0.35188288072409385})"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "zEQau1MAALCz"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "model.save('anpr-v1.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWvIFV7vAOBE"
      },
      "source": [
        "# Test and predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "98ycDW8OAPH7"
      },
      "outputs": [],
      "source": [
        "# to predict test image\n",
        "def predict_and_plot(path_test_car):\n",
        "\n",
        "    results = model.predict(path_test_car, device='cpu')\n",
        "\n",
        "\n",
        "    image = cv2.imread(path_test_car)\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            confidence = box.conf[0]\n",
        "\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            cv2.putText(image, f'{confidence*100:.2f}%', (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "2yHv9s35AUK1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "a91bc0ba-1409-4157-8dc6-8c698e4f5d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars425.png: 160x320 1 license_plate, 39.1ms\n",
            "Speed: 0.9ms preprocess, 39.1ms inference, 17.0ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "predict_and_plot(test.iloc[0].img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "o_4kpvffAdmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "5c16df6e-7a06-4809-d3b1-c7ab2634fb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars181.png: 320x192 1 license_plate, 51.2ms\n",
            "Speed: 0.9ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 192)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "predict_and_plot(test.iloc[2].img_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "_eRhkU9KcTke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "def batch_predict_and_save(model, test_df, output_dir='predictions'):\n",
        "    \"\"\"\n",
        "    Run ANPR predictions on all images in the test dataset and save results\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        test_df: DataFrame containing test image paths\n",
        "        output_dir: Directory to save annotated images\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Process all test images\n",
        "    results_dict = {}\n",
        "\n",
        "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing images\"):\n",
        "        img_path = row['img_path']\n",
        "        img_name = os.path.basename(img_path)\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(img_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Read and convert image\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Store detection results\n",
        "        detections = []\n",
        "\n",
        "        # Draw bounding boxes and confidence scores\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                confidence = float(box.conf[0])\n",
        "\n",
        "                # Draw rectangle and confidence score\n",
        "                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(image, f'{confidence*100:.2f}%',\n",
        "                           (x1, y1 - 10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                           0.9,\n",
        "                           (255, 0, 0),\n",
        "                           2)\n",
        "\n",
        "                detections.append({\n",
        "                    'bbox': [x1, y1, x2, y2],\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "        # Save results\n",
        "        results_dict[img_name] = {\n",
        "            'detections': detections,\n",
        "            'original_path': img_path\n",
        "        }\n",
        "\n",
        "        # Save annotated image\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(os.path.join(output_dir, f'annotated_{img_name}'),\n",
        "                   bbox_inches='tight',\n",
        "                   pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "    return results_dict\n",
        "\n",
        "# Function to display summary statistics\n",
        "def display_detection_stats(results_dict):\n",
        "    \"\"\"\n",
        "    Display summary statistics for the batch predictions\n",
        "\n",
        "    Args:\n",
        "        results_dict: Dictionary containing detection results\n",
        "    \"\"\"\n",
        "    total_images = len(results_dict)\n",
        "    images_with_detections = sum(1 for v in results_dict.values() if v['detections'])\n",
        "    total_detections = sum(len(v['detections']) for v in results_dict.values())\n",
        "    avg_confidence = np.mean([d['confidence']\n",
        "                            for v in results_dict.values()\n",
        "                            for d in v['detections']]) if total_detections > 0 else 0\n",
        "\n",
        "    print(f\"Detection Summary:\")\n",
        "    print(f\"Total images processed: {total_images}\")\n",
        "    print(f\"Images with detections: {images_with_detections}\")\n",
        "    print(f\"Total license plates detected: {total_detections}\")\n",
        "    print(f\"Average confidence score: {avg_confidence*100:.2f}%\")\n",
        "\n",
        "# Usage example\n",
        "def run_batch_detection(model, test_df):\n",
        "    \"\"\"\n",
        "    Run the complete batch detection pipeline\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        test_df: DataFrame containing test image paths\n",
        "    \"\"\"\n",
        "    print(\"Starting batch license plate detection...\")\n",
        "\n",
        "    # Run predictions on all images\n",
        "    results = batch_predict_and_save(model, test_df)\n",
        "\n",
        "    # Display statistics\n",
        "    display_detection_stats(results)\n",
        "\n",
        "    print(f\"\\nPredictions saved in 'predictions' directory\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "7PWAwFFKcWrH"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign train to train_data\n",
        "train_data = train\n",
        "\n",
        "# Run batch prediction\n",
        "run_batch_detection(model=model, test_df=train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjSx558DIafN",
        "outputId": "91a248e2-8451-4057-94e3-688e22c57e5c"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting batch license plate detection...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   0%|          | 0/345 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars124.png: 224x320 1 license_plate, 68.0ms\n",
            "Speed: 1.3ms preprocess, 68.0ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   0%|          | 1/345 [00:00<02:13,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars315.png: 256x320 1 license_plate, 66.8ms\n",
            "Speed: 1.1ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   1%|          | 2/345 [00:00<02:11,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars282.png: 256x320 1 license_plate, 53.4ms\n",
            "Speed: 1.2ms preprocess, 53.4ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   1%|          | 3/345 [00:01<02:13,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars236.png: 160x320 1 license_plate, 44.1ms\n",
            "Speed: 0.8ms preprocess, 44.1ms inference, 0.9ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   1%|          | 4/345 [00:01<02:01,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars112.png: 320x192 1 license_plate, 50.3ms\n",
            "Speed: 0.9ms preprocess, 50.3ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 192)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   1%|▏         | 5/345 [00:01<01:59,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars402.png: 192x320 1 license_plate, 43.8ms\n",
            "Speed: 0.9ms preprocess, 43.8ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   2%|▏         | 6/345 [00:02<01:59,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars105.png: 192x320 2 license_plates, 50.9ms\n",
            "Speed: 1.2ms preprocess, 50.9ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   2%|▏         | 7/345 [00:02<01:52,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars358.png: 160x320 2 license_plates, 27.3ms\n",
            "Speed: 0.7ms preprocess, 27.3ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   2%|▏         | 8/345 [00:02<01:40,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars180.png: 256x320 1 license_plate, 36.3ms\n",
            "Speed: 0.8ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   3%|▎         | 9/345 [00:02<01:35,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars280.png: 224x320 1 license_plate, 31.0ms\n",
            "Speed: 0.7ms preprocess, 31.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   3%|▎         | 10/345 [00:03<01:37,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars265.png: 192x320 1 license_plate, 29.5ms\n",
            "Speed: 0.9ms preprocess, 29.5ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   3%|▎         | 11/345 [00:03<01:30,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars230.png: 192x320 1 license_plate, 30.1ms\n",
            "Speed: 0.6ms preprocess, 30.1ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   3%|▎         | 12/345 [00:03<01:28,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars386.png: 256x320 1 license_plate, 38.9ms\n",
            "Speed: 0.9ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   4%|▍         | 13/345 [00:03<01:28,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars275.png: 192x320 1 license_plate, 32.9ms\n",
            "Speed: 0.6ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   4%|▍         | 14/345 [00:04<01:25,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars424.png: 256x320 1 license_plate, 35.6ms\n",
            "Speed: 0.8ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   4%|▍         | 15/345 [00:04<01:26,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars11.png: 256x320 1 license_plate, 33.6ms\n",
            "Speed: 0.8ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   5%|▍         | 16/345 [00:04<01:26,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars390.png: 256x320 1 license_plate, 34.3ms\n",
            "Speed: 0.9ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   5%|▍         | 17/345 [00:05<01:26,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars51.png: 224x320 1 license_plate, 32.8ms\n",
            "Speed: 0.7ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   5%|▌         | 18/345 [00:05<01:25,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars309.png: 192x320 1 license_plate, 28.8ms\n",
            "Speed: 2.0ms preprocess, 28.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   6%|▌         | 19/345 [00:05<01:21,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars226.png: 224x320 1 license_plate, 33.6ms\n",
            "Speed: 0.7ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   6%|▌         | 20/345 [00:05<01:21,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars273.png: 192x320 1 license_plate, 29.0ms\n",
            "Speed: 0.7ms preprocess, 29.0ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   6%|▌         | 21/345 [00:06<01:20,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars380.png: 192x320 1 license_plate, 27.5ms\n",
            "Speed: 0.9ms preprocess, 27.5ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   6%|▋         | 22/345 [00:06<01:18,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars31.png: 224x320 1 license_plate, 32.1ms\n",
            "Speed: 1.3ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   7%|▋         | 23/345 [00:06<01:17,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars418.png: 192x320 1 license_plate, 31.7ms\n",
            "Speed: 0.6ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   7%|▋         | 24/345 [00:06<01:16,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars257.png: 256x320 1 license_plate, 33.7ms\n",
            "Speed: 0.8ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   7%|▋         | 25/345 [00:06<01:18,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars92.png: 224x320 1 license_plate, 32.0ms\n",
            "Speed: 1.0ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   8%|▊         | 26/345 [00:07<01:19,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars344.png: 224x320 1 license_plate, 33.8ms\n",
            "Speed: 1.0ms preprocess, 33.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   8%|▊         | 27/345 [00:07<01:20,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars26.png: 192x320 1 license_plate, 29.1ms\n",
            "Speed: 0.7ms preprocess, 29.1ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   8%|▊         | 28/345 [00:07<01:18,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars157.png: 224x320 2 license_plates, 33.6ms\n",
            "Speed: 0.9ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   8%|▊         | 29/345 [00:07<01:18,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars76.png: 256x320 1 license_plate, 48.3ms\n",
            "Speed: 1.2ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   9%|▊         | 30/345 [00:08<01:21,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars79.png: 288x320 1 license_plate, 41.8ms\n",
            "Speed: 1.0ms preprocess, 41.8ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   9%|▉         | 31/345 [00:08<01:25,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars427.png: 256x320 1 license_plate, 33.1ms\n",
            "Speed: 1.0ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   9%|▉         | 32/345 [00:08<01:25,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars74.png: 224x320 1 license_plate, 31.1ms\n",
            "Speed: 0.8ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  10%|▉         | 33/345 [00:09<01:23,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars41.png: 320x256 1 license_plate, 34.1ms\n",
            "Speed: 0.9ms preprocess, 34.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  10%|▉         | 34/345 [00:09<01:23,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars310.png: 288x320 1 license_plate, 40.8ms\n",
            "Speed: 0.9ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  10%|█         | 35/345 [00:09<01:26,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars242.png: 320x320 1 license_plate, 38.0ms\n",
            "Speed: 1.6ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  10%|█         | 36/345 [00:09<01:29,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars406.png: 224x320 1 license_plate, 32.0ms\n",
            "Speed: 0.9ms preprocess, 32.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  11%|█         | 37/345 [00:10<01:26,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars145.png: 224x320 1 license_plate, 30.9ms\n",
            "Speed: 0.9ms preprocess, 30.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  11%|█         | 38/345 [00:10<01:23,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars189.png: 224x320 1 license_plate, 33.5ms\n",
            "Speed: 0.8ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  11%|█▏        | 39/345 [00:10<01:21,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars291.png: 192x320 1 license_plate, 27.3ms\n",
            "Speed: 1.1ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  12%|█▏        | 40/345 [00:10<01:18,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars176.png: 224x320 1 license_plate, 32.8ms\n",
            "Speed: 1.1ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  12%|█▏        | 41/345 [00:11<01:16,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars232.png: 256x320 1 license_plate, 32.4ms\n",
            "Speed: 0.8ms preprocess, 32.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  12%|█▏        | 42/345 [00:11<01:16,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars381.png: 192x320 1 license_plate, 28.0ms\n",
            "Speed: 0.8ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  12%|█▏        | 43/345 [00:11<01:14,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars222.png: 192x320 1 license_plate, 26.5ms\n",
            "Speed: 0.9ms preprocess, 26.5ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  13%|█▎        | 44/345 [00:11<01:11,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars44.png: 256x320 1 license_plate, 35.8ms\n",
            "Speed: 0.9ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  13%|█▎        | 45/345 [00:12<01:15,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars313.png: 256x320 1 license_plate, 34.4ms\n",
            "Speed: 1.0ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  13%|█▎        | 46/345 [00:12<01:20,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars296.png: 256x320 1 license_plate, 52.2ms\n",
            "Speed: 1.3ms preprocess, 52.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  14%|█▎        | 47/345 [00:12<01:33,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars303.png: 256x320 1 license_plate, 52.1ms\n",
            "Speed: 1.4ms preprocess, 52.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  14%|█▍        | 48/345 [00:13<01:40,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars301.png: 160x320 1 license_plate, 37.1ms\n",
            "Speed: 0.8ms preprocess, 37.1ms inference, 0.8ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  14%|█▍        | 49/345 [00:13<01:36,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars379.png: 288x320 1 license_plate, 56.5ms\n",
            "Speed: 1.2ms preprocess, 56.5ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  14%|█▍        | 50/345 [00:14<01:45,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars350.png: 224x320 1 license_plate, 52.7ms\n",
            "Speed: 1.1ms preprocess, 52.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  15%|█▍        | 51/345 [00:14<01:42,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars361.png: 256x320 1 license_plate, 48.1ms\n",
            "Speed: 1.1ms preprocess, 48.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  15%|█▌        | 52/345 [00:14<01:42,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars137.png: 224x320 1 license_plate, 43.8ms\n",
            "Speed: 1.1ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  15%|█▌        | 53/345 [00:15<01:41,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars248.png: 256x320 1 license_plate, 52.7ms\n",
            "Speed: 1.2ms preprocess, 52.7ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  16%|█▌        | 54/345 [00:15<01:43,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars239.png: 256x320 1 license_plate, 53.0ms\n",
            "Speed: 1.3ms preprocess, 53.0ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  16%|█▌        | 55/345 [00:15<01:46,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars90.png: 256x320 1 license_plate, 54.3ms\n",
            "Speed: 1.3ms preprocess, 54.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  16%|█▌        | 56/345 [00:16<01:51,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars256.png: 224x320 1 license_plate, 51.1ms\n",
            "Speed: 2.3ms preprocess, 51.1ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  17%|█▋        | 57/345 [00:16<01:47,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars359.png: 256x320 1 license_plate, 51.8ms\n",
            "Speed: 1.1ms preprocess, 51.8ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  17%|█▋        | 58/345 [00:16<01:47,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars88.png: 256x320 1 license_plate, 53.9ms\n",
            "Speed: 1.1ms preprocess, 53.9ms inference, 4.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  17%|█▋        | 59/345 [00:17<01:49,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars205.png: 320x320 2 license_plates, 56.4ms\n",
            "Speed: 1.4ms preprocess, 56.4ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  17%|█▋        | 60/345 [00:17<01:55,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars314.png: 192x320 1 license_plate, 44.6ms\n",
            "Speed: 0.9ms preprocess, 44.6ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  18%|█▊        | 61/345 [00:18<01:50,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars162.png: 192x320 1 license_plate, 42.8ms\n",
            "Speed: 1.0ms preprocess, 42.8ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  18%|█▊        | 62/345 [00:18<01:46,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars99.png: 320x256 1 license_plate, 52.6ms\n",
            "Speed: 1.2ms preprocess, 52.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  18%|█▊        | 63/345 [00:18<01:49,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars64.png: 224x320 1 license_plate, 52.6ms\n",
            "Speed: 1.2ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  19%|█▊        | 64/345 [00:19<01:49,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars16.png: 192x320 (no detections), 47.2ms\n",
            "Speed: 5.5ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  19%|█▉        | 65/345 [00:19<01:44,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars7.png: 224x320 1 license_plate, 48.8ms\n",
            "Speed: 1.1ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  19%|█▉        | 66/345 [00:20<01:46,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars191.png: 224x320 1 license_plate, 53.6ms\n",
            "Speed: 1.2ms preprocess, 53.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  19%|█▉        | 67/345 [00:20<01:46,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars6.png: 256x320 1 license_plate, 52.4ms\n",
            "Speed: 1.2ms preprocess, 52.4ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  20%|█▉        | 68/345 [00:20<01:47,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars142.png: 160x320 1 license_plate, 39.2ms\n",
            "Speed: 0.8ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  20%|██        | 69/345 [00:21<01:41,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars179.png: 224x320 1 license_plate, 54.6ms\n",
            "Speed: 1.2ms preprocess, 54.6ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  20%|██        | 70/345 [00:21<01:42,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars209.png: 256x320 1 license_plate, 52.6ms\n",
            "Speed: 1.1ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  21%|██        | 71/345 [00:21<01:41,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars285.png: 224x320 1 license_plate, 50.2ms\n",
            "Speed: 1.1ms preprocess, 50.2ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  21%|██        | 72/345 [00:22<01:34,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars300.png: 192x320 1 license_plate, 30.5ms\n",
            "Speed: 1.1ms preprocess, 30.5ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  21%|██        | 73/345 [00:22<01:24,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars153.png: 192x320 1 license_plate, 29.3ms\n",
            "Speed: 1.0ms preprocess, 29.3ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  21%|██▏       | 74/345 [00:22<01:17,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars121.png: 256x320 1 license_plate, 33.9ms\n",
            "Speed: 0.7ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  22%|██▏       | 75/345 [00:22<01:15,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars166.png: 320x256 1 license_plate, 33.3ms\n",
            "Speed: 0.7ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  22%|██▏       | 76/345 [00:23<01:14,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars61.png: 256x320 1 license_plate, 42.0ms\n",
            "Speed: 1.4ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  22%|██▏       | 77/345 [00:23<01:15,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars62.png: 256x320 1 license_plate, 36.1ms\n",
            "Speed: 1.2ms preprocess, 36.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  23%|██▎       | 78/345 [00:23<01:14,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars252.png: 256x320 1 license_plate, 34.4ms\n",
            "Speed: 0.9ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  23%|██▎       | 79/345 [00:24<01:13,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars227.png: 224x320 3 license_plates, 35.5ms\n",
            "Speed: 1.0ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  23%|██▎       | 80/345 [00:24<01:12,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars202.png: 256x320 1 license_plate, 34.7ms\n",
            "Speed: 1.1ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  23%|██▎       | 81/345 [00:24<01:11,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars422.png: 192x320 1 license_plate, 28.6ms\n",
            "Speed: 0.7ms preprocess, 28.6ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  24%|██▍       | 82/345 [00:24<01:08,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars71.png: 192x320 1 license_plate, 28.2ms\n",
            "Speed: 1.0ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  24%|██▍       | 83/345 [00:25<01:05,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars81.png: 256x320 1 license_plate, 33.1ms\n",
            "Speed: 1.1ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  24%|██▍       | 84/345 [00:25<01:06,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars133.png: 224x320 1 license_plate, 35.3ms\n",
            "Speed: 1.2ms preprocess, 35.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  25%|██▍       | 85/345 [00:25<01:08,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars170.png: 256x320 1 license_plate, 48.9ms\n",
            "Speed: 1.4ms preprocess, 48.9ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  25%|██▍       | 86/345 [00:25<01:10,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars333.png: 224x320 1 license_plate, 33.1ms\n",
            "Speed: 1.1ms preprocess, 33.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  25%|██▌       | 87/345 [00:26<01:09,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars138.png: 256x320 2 license_plates, 42.3ms\n",
            "Speed: 1.2ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  26%|██▌       | 88/345 [00:26<01:09,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars410.png: 320x256 1 license_plate, 35.5ms\n",
            "Speed: 0.8ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  26%|██▌       | 89/345 [00:26<01:08,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars10.png: 192x320 1 license_plate, 27.6ms\n",
            "Speed: 1.3ms preprocess, 27.6ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  26%|██▌       | 90/345 [00:26<01:04,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars238.png: 224x320 1 license_plate, 33.1ms\n",
            "Speed: 1.1ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  26%|██▋       | 91/345 [00:27<01:05,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars216.png: 256x320 1 license_plate, 32.5ms\n",
            "Speed: 1.3ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  27%|██▋       | 92/345 [00:27<01:06,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars94.png: 256x320 1 license_plate, 32.5ms\n",
            "Speed: 1.1ms preprocess, 32.5ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  27%|██▋       | 93/345 [00:27<01:06,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars288.png: 192x320 1 license_plate, 30.8ms\n",
            "Speed: 1.3ms preprocess, 30.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  27%|██▋       | 94/345 [00:27<01:02,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars149.png: 256x320 1 license_plate, 37.1ms\n",
            "Speed: 1.1ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  28%|██▊       | 95/345 [00:28<01:04,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars212.png: 256x320 1 license_plate, 31.7ms\n",
            "Speed: 1.1ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  28%|██▊       | 96/345 [00:28<01:04,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars188.png: 320x256 (no detections), 35.9ms\n",
            "Speed: 1.3ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  28%|██▊       | 97/345 [00:28<01:04,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars383.png: 224x320 2 license_plates, 37.6ms\n",
            "Speed: 1.0ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  28%|██▊       | 98/345 [00:28<01:04,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars119.png: 224x320 1 license_plate, 32.3ms\n",
            "Speed: 1.0ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  29%|██▊       | 99/345 [00:29<01:02,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars123.png: 256x320 1 license_plate, 34.7ms\n",
            "Speed: 1.1ms preprocess, 34.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  29%|██▉       | 100/345 [00:29<01:03,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars426.png: 256x320 1 license_plate, 37.1ms\n",
            "Speed: 1.2ms preprocess, 37.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  29%|██▉       | 101/345 [00:29<01:03,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars15.png: 224x320 1 license_plate, 34.0ms\n",
            "Speed: 1.4ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  30%|██▉       | 102/345 [00:30<01:02,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars251.png: 192x320 (no detections), 36.3ms\n",
            "Speed: 1.0ms preprocess, 36.3ms inference, 0.4ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  30%|██▉       | 103/345 [00:30<01:01,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars371.png: 160x320 1 license_plate, 27.4ms\n",
            "Speed: 0.8ms preprocess, 27.4ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  30%|███       | 104/345 [00:30<00:57,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars19.png: 192x320 1 license_plate, 32.8ms\n",
            "Speed: 1.1ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  30%|███       | 105/345 [00:30<00:57,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars385.png: 224x320 1 license_plate, 36.3ms\n",
            "Speed: 1.4ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  31%|███       | 106/345 [00:30<00:58,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars327.png: 224x320 1 license_plate, 35.2ms\n",
            "Speed: 2.2ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  31%|███       | 107/345 [00:31<00:58,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars394.png: 256x320 1 license_plate, 35.5ms\n",
            "Speed: 1.1ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  31%|███▏      | 108/345 [00:31<01:01,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars217.png: 192x320 1 license_plate, 27.6ms\n",
            "Speed: 1.0ms preprocess, 27.6ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  32%|███▏      | 109/345 [00:31<00:59,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars322.png: 288x320 1 license_plate, 37.2ms\n",
            "Speed: 1.3ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  32%|███▏      | 110/345 [00:32<01:01,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars367.png: 224x320 1 license_plate, 46.7ms\n",
            "Speed: 1.1ms preprocess, 46.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  32%|███▏      | 111/345 [00:32<01:10,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars197.png: 192x320 1 license_plate, 41.3ms\n",
            "Speed: 1.3ms preprocess, 41.3ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  32%|███▏      | 112/345 [00:32<01:10,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars276.png: 224x320 1 license_plate, 50.7ms\n",
            "Speed: 1.0ms preprocess, 50.7ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  33%|███▎      | 113/345 [00:33<01:16,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars378.png: 256x320 1 license_plate, 54.3ms\n",
            "Speed: 1.1ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  33%|███▎      | 114/345 [00:33<01:16,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars420.png: 256x320 1 license_plate, 55.6ms\n",
            "Speed: 1.2ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  33%|███▎      | 115/345 [00:33<01:22,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars125.png: 224x320 1 license_plate, 47.2ms\n",
            "Speed: 1.4ms preprocess, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  34%|███▎      | 116/345 [00:34<01:23,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars347.png: 192x320 1 license_plate, 43.6ms\n",
            "Speed: 0.8ms preprocess, 43.6ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  34%|███▍      | 117/345 [00:34<01:17,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars136.png: 224x320 1 license_plate, 51.7ms\n",
            "Speed: 1.0ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  34%|███▍      | 118/345 [00:34<01:18,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars311.png: 224x320 1 license_plate, 49.7ms\n",
            "Speed: 1.1ms preprocess, 49.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  34%|███▍      | 119/345 [00:35<01:21,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars117.png: 160x320 1 license_plate, 41.8ms\n",
            "Speed: 0.9ms preprocess, 41.8ms inference, 0.9ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  35%|███▍      | 120/345 [00:35<01:17,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars317.png: 256x320 1 license_plate, 58.1ms\n",
            "Speed: 1.2ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  35%|███▌      | 121/345 [00:35<01:19,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars218.png: 224x320 (no detections), 50.9ms\n",
            "Speed: 1.0ms preprocess, 50.9ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  35%|███▌      | 122/345 [00:36<01:21,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars167.png: 256x320 1 license_plate, 52.0ms\n",
            "Speed: 1.3ms preprocess, 52.0ms inference, 2.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  36%|███▌      | 123/345 [00:36<01:25,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars156.png: 160x320 1 license_plate, 39.0ms\n",
            "Speed: 0.8ms preprocess, 39.0ms inference, 0.9ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  36%|███▌      | 124/345 [00:37<01:20,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars338.png: 224x320 (no detections), 70.3ms\n",
            "Speed: 1.1ms preprocess, 70.3ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  36%|███▌      | 125/345 [00:37<01:19,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars80.png: 256x320 1 license_plate, 55.1ms\n",
            "Speed: 1.1ms preprocess, 55.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  37%|███▋      | 126/345 [00:37<01:21,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars210.png: 224x320 1 license_plate, 67.5ms\n",
            "Speed: 1.0ms preprocess, 67.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  37%|███▋      | 127/345 [00:38<01:24,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars249.png: 224x320 2 license_plates, 64.9ms\n",
            "Speed: 1.0ms preprocess, 64.9ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  37%|███▋      | 128/345 [00:38<01:27,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars382.png: 256x320 1 license_plate, 59.5ms\n",
            "Speed: 1.1ms preprocess, 59.5ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  37%|███▋      | 129/345 [00:39<01:28,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars407.png: 224x320 1 license_plate, 48.3ms\n",
            "Speed: 1.2ms preprocess, 48.3ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  38%|███▊      | 130/345 [00:39<01:26,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars139.png: 256x320 1 license_plate, 58.9ms\n",
            "Speed: 1.3ms preprocess, 58.9ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  38%|███▊      | 131/345 [00:40<01:29,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars60.png: 256x320 1 license_plate, 58.3ms\n",
            "Speed: 1.1ms preprocess, 58.3ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  38%|███▊      | 132/345 [00:40<01:28,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars413.png: 224x320 1 license_plate, 48.2ms\n",
            "Speed: 1.2ms preprocess, 48.2ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  39%|███▊      | 133/345 [00:40<01:18,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars339.png: 192x320 1 license_plate, 28.6ms\n",
            "Speed: 0.9ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  39%|███▉      | 134/345 [00:40<01:09,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars266.png: 192x320 1 license_plate, 29.9ms\n",
            "Speed: 0.8ms preprocess, 29.9ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  39%|███▉      | 135/345 [00:41<01:02,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars308.png: 256x320 1 license_plate, 50.4ms\n",
            "Speed: 1.2ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  39%|███▉      | 136/345 [00:41<01:01,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars115.png: 256x320 1 license_plate, 40.2ms\n",
            "Speed: 1.2ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  40%|███▉      | 137/345 [00:41<01:00,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars290.png: 224x320 2 license_plates, 31.7ms\n",
            "Speed: 1.0ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  40%|████      | 138/345 [00:41<00:57,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars388.png: 256x320 1 license_plate, 41.1ms\n",
            "Speed: 1.3ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  40%|████      | 139/345 [00:42<00:58,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars267.png: 192x320 1 license_plate, 28.8ms\n",
            "Speed: 1.0ms preprocess, 28.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  41%|████      | 140/345 [00:42<00:54,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars118.png: 224x320 1 license_plate, 39.9ms\n",
            "Speed: 1.1ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  41%|████      | 141/345 [00:42<00:53,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars34.png: 288x320 2 license_plates, 38.0ms\n",
            "Speed: 1.2ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  41%|████      | 142/345 [00:43<00:54,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars183.png: 192x320 1 license_plate, 33.5ms\n",
            "Speed: 1.2ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  41%|████▏     | 143/345 [00:43<00:54,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars343.png: 256x320 1 license_plate, 41.5ms\n",
            "Speed: 1.2ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  42%|████▏     | 144/345 [00:43<00:54,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars373.png: 192x320 1 license_plate, 29.4ms\n",
            "Speed: 0.9ms preprocess, 29.4ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  42%|████▏     | 145/345 [00:43<00:51,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars95.png: 224x320 1 license_plate, 31.0ms\n",
            "Speed: 0.9ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  42%|████▏     | 146/345 [00:44<00:52,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars293.png: 224x320 1 license_plate, 35.8ms\n",
            "Speed: 1.1ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  43%|████▎     | 147/345 [00:44<00:52,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars146.png: 256x320 (no detections), 39.1ms\n",
            "Speed: 1.2ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  43%|████▎     | 148/345 [00:44<00:52,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars283.png: 192x320 (no detections), 34.3ms\n",
            "Speed: 0.9ms preprocess, 34.3ms inference, 0.3ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  43%|████▎     | 149/345 [00:44<00:49,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars32.png: 256x320 1 license_plate, 35.7ms\n",
            "Speed: 0.7ms preprocess, 35.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  43%|████▎     | 150/345 [00:45<00:49,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars38.png: 320x320 1 license_plate, 46.7ms\n",
            "Speed: 1.8ms preprocess, 46.7ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  44%|████▍     | 151/345 [00:45<00:54,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars328.png: 192x320 1 license_plate, 30.8ms\n",
            "Speed: 1.5ms preprocess, 30.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  44%|████▍     | 152/345 [00:45<00:50,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars193.png: 224x320 1 license_plate, 34.7ms\n",
            "Speed: 1.0ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  44%|████▍     | 153/345 [00:45<00:50,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars57.png: 192x320 1 license_plate, 30.4ms\n",
            "Speed: 0.9ms preprocess, 30.4ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  45%|████▍     | 154/345 [00:46<00:47,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars278.png: 192x320 1 license_plate, 39.9ms\n",
            "Speed: 0.9ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  45%|████▍     | 155/345 [00:46<00:46,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars4.png: 192x320 1 license_plate, 32.1ms\n",
            "Speed: 1.3ms preprocess, 32.1ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  45%|████▌     | 156/345 [00:46<00:47,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars261.png: 256x320 2 license_plates, 33.6ms\n",
            "Speed: 1.9ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  46%|████▌     | 157/345 [00:46<00:47,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars387.png: 224x320 1 license_plate, 34.3ms\n",
            "Speed: 1.2ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  46%|████▌     | 158/345 [00:47<00:47,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars325.png: 192x320 (no detections), 38.1ms\n",
            "Speed: 1.0ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  46%|████▌     | 159/345 [00:47<00:45,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars393.png: 192x320 1 license_plate, 37.1ms\n",
            "Speed: 1.8ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  46%|████▋     | 160/345 [00:47<00:45,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars326.png: 256x320 1 license_plate, 33.6ms\n",
            "Speed: 1.1ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  47%|████▋     | 161/345 [00:47<00:45,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars295.png: 224x320 1 license_plate, 34.4ms\n",
            "Speed: 1.2ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  47%|████▋     | 162/345 [00:48<00:45,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars192.png: 256x320 1 license_plate, 47.2ms\n",
            "Speed: 1.3ms preprocess, 47.2ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  47%|████▋     | 163/345 [00:48<00:46,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars48.png: 192x320 1 license_plate, 36.4ms\n",
            "Speed: 1.3ms preprocess, 36.4ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  48%|████▊     | 164/345 [00:48<00:45,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars171.png: 224x320 1 license_plate, 32.0ms\n",
            "Speed: 1.2ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  48%|████▊     | 165/345 [00:48<00:45,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars151.png: 224x320 1 license_plate, 32.2ms\n",
            "Speed: 1.0ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  48%|████▊     | 166/345 [00:49<00:44,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars27.png: 192x320 1 license_plate, 38.2ms\n",
            "Speed: 0.9ms preprocess, 38.2ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  48%|████▊     | 167/345 [00:49<00:43,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars174.png: 192x320 (no detections), 32.0ms\n",
            "Speed: 0.9ms preprocess, 32.0ms inference, 0.4ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  49%|████▊     | 168/345 [00:50<01:40,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars97.png: 256x320 1 license_plate, 51.5ms\n",
            "Speed: 1.3ms preprocess, 51.5ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  49%|████▉     | 169/345 [00:51<01:31,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars221.png: 192x320 (no detections), 46.5ms\n",
            "Speed: 1.0ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  49%|████▉     | 170/345 [00:51<01:20,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars177.png: 192x320 1 license_plate, 41.5ms\n",
            "Speed: 1.0ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  50%|████▉     | 171/345 [00:51<01:13,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars2.png: 320x320 1 license_plate, 67.8ms\n",
            "Speed: 1.6ms preprocess, 67.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  50%|████▉     | 172/345 [00:52<01:14,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars404.png: 320x320 1 license_plate, 62.2ms\n",
            "Speed: 1.5ms preprocess, 62.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  50%|█████     | 173/345 [00:52<01:12,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars391.png: 192x320 1 license_plate, 50.2ms\n",
            "Speed: 1.0ms preprocess, 50.2ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  50%|█████     | 174/345 [00:52<01:09,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars432.png: 224x320 1 license_plate, 46.5ms\n",
            "Speed: 1.2ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  51%|█████     | 175/345 [00:53<01:06,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars336.png: 256x320 1 license_plate, 65.1ms\n",
            "Speed: 1.3ms preprocess, 65.1ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  51%|█████     | 176/345 [00:53<01:05,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars294.png: 224x320 1 license_plate, 58.4ms\n",
            "Speed: 1.2ms preprocess, 58.4ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  51%|█████▏    | 177/345 [00:54<01:02,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars244.png: 256x320 1 license_plate, 61.0ms\n",
            "Speed: 1.4ms preprocess, 61.0ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  52%|█████▏    | 178/345 [00:54<01:04,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars224.png: 256x320 2 license_plates, 63.3ms\n",
            "Speed: 1.3ms preprocess, 63.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  52%|█████▏    | 179/345 [00:54<01:06,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars127.png: 224x320 1 license_plate, 56.3ms\n",
            "Speed: 1.1ms preprocess, 56.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  52%|█████▏    | 180/345 [00:55<01:05,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars195.png: 192x320 2 license_plates, 47.2ms\n",
            "Speed: 2.8ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  52%|█████▏    | 181/345 [00:55<01:03,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars234.png: 192x320 1 license_plate, 49.0ms\n",
            "Speed: 1.3ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  53%|█████▎    | 182/345 [00:55<01:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars351.png: 192x320 1 license_plate, 50.8ms\n",
            "Speed: 0.9ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  53%|█████▎    | 183/345 [00:56<00:57,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars120.png: 224x320 1 license_plate, 55.9ms\n",
            "Speed: 1.1ms preprocess, 55.9ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  53%|█████▎    | 184/345 [00:56<00:58,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars316.png: 256x320 (no detections), 55.9ms\n",
            "Speed: 1.4ms preprocess, 55.9ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  54%|█████▎    | 185/345 [00:57<01:01,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars319.png: 288x320 1 license_plate, 82.7ms\n",
            "Speed: 1.3ms preprocess, 82.7ms inference, 0.9ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  54%|█████▍    | 186/345 [00:57<01:05,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars264.png: 320x320 1 license_plate, 68.1ms\n",
            "Speed: 1.4ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  54%|█████▍    | 187/345 [00:58<01:09,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars59.png: 256x320 1 license_plate, 58.9ms\n",
            "Speed: 7.7ms preprocess, 58.9ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  54%|█████▍    | 188/345 [00:58<01:05,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars29.png: 256x320 2 license_plates, 61.8ms\n",
            "Speed: 1.2ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  55%|█████▍    | 189/345 [00:58<01:04,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars160.png: 192x320 1 license_plate, 46.5ms\n",
            "Speed: 1.2ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  55%|█████▌    | 190/345 [00:59<01:01,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars412.png: 192x320 1 license_plate, 55.6ms\n",
            "Speed: 1.4ms preprocess, 55.6ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  55%|█████▌    | 191/345 [00:59<00:57,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars101.png: 256x320 1 license_plate, 40.0ms\n",
            "Speed: 1.3ms preprocess, 40.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  56%|█████▌    | 192/345 [00:59<00:52,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars53.png: 256x320 1 license_plate, 41.2ms\n",
            "Speed: 1.2ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  56%|█████▌    | 193/345 [01:00<00:48,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars334.png: 192x320 1 license_plate, 54.8ms\n",
            "Speed: 1.0ms preprocess, 54.8ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  56%|█████▌    | 194/345 [01:00<00:45,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars186.png: 192x320 1 license_plate, 31.8ms\n",
            "Speed: 2.3ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  57%|█████▋    | 195/345 [01:00<00:42,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars346.png: 224x320 1 license_plate, 33.5ms\n",
            "Speed: 1.3ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  57%|█████▋    | 196/345 [01:00<00:40,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars299.png: 256x320 1 license_plate, 39.0ms\n",
            "Speed: 1.3ms preprocess, 39.0ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  57%|█████▋    | 197/345 [01:01<00:39,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars332.png: 192x320 1 license_plate, 38.5ms\n",
            "Speed: 1.1ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  57%|█████▋    | 198/345 [01:01<00:39,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars260.png: 192x320 1 license_plate, 30.9ms\n",
            "Speed: 1.2ms preprocess, 30.9ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  58%|█████▊    | 199/345 [01:01<00:37,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars354.png: 224x320 1 license_plate, 33.5ms\n",
            "Speed: 1.2ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  58%|█████▊    | 200/345 [01:01<00:37,  3.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars58.png: 224x320 1 license_plate, 35.6ms\n",
            "Speed: 1.8ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  58%|█████▊    | 201/345 [01:02<00:36,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars18.png: 256x320 1 license_plate, 38.4ms\n",
            "Speed: 1.3ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  59%|█████▊    | 202/345 [01:02<00:37,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars135.png: 192x320 1 license_plate, 32.8ms\n",
            "Speed: 1.0ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  59%|█████▉    | 203/345 [01:02<00:35,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars405.png: 192x320 1 license_plate, 34.0ms\n",
            "Speed: 1.1ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  59%|█████▉    | 204/345 [01:02<00:35,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars35.png: 224x320 1 license_plate, 35.2ms\n",
            "Speed: 1.3ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  59%|█████▉    | 205/345 [01:03<00:35,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars223.png: 224x320 1 license_plate, 40.1ms\n",
            "Speed: 1.4ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  60%|█████▉    | 206/345 [01:03<00:36,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars63.png: 224x320 1 license_plate, 34.6ms\n",
            "Speed: 1.4ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  60%|██████    | 207/345 [01:03<00:36,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars320.png: 320x256 1 license_plate, 40.9ms\n",
            "Speed: 1.3ms preprocess, 40.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  60%|██████    | 208/345 [01:03<00:36,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars286.png: 256x320 1 license_plate, 40.4ms\n",
            "Speed: 1.3ms preprocess, 40.4ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  61%|██████    | 209/345 [01:04<00:36,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars113.png: 256x320 1 license_plate, 42.6ms\n",
            "Speed: 1.2ms preprocess, 42.6ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  61%|██████    | 210/345 [01:04<00:37,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars104.png: 256x320 1 license_plate, 45.5ms\n",
            "Speed: 1.2ms preprocess, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  61%|██████    | 211/345 [01:04<00:37,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars122.png: 256x320 1 license_plate, 36.5ms\n",
            "Speed: 1.2ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  61%|██████▏   | 212/345 [01:05<00:36,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars272.png: 160x320 1 license_plate, 28.0ms\n",
            "Speed: 1.3ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  62%|██████▏   | 213/345 [01:05<00:33,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars49.png: 224x320 1 license_plate, 48.4ms\n",
            "Speed: 1.3ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  62%|██████▏   | 214/345 [01:05<00:33,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars345.png: 256x320 1 license_plate, 39.6ms\n",
            "Speed: 1.5ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  62%|██████▏   | 215/345 [01:05<00:33,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars258.png: 224x320 1 license_plate, 35.4ms\n",
            "Speed: 1.2ms preprocess, 35.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  63%|██████▎   | 216/345 [01:05<00:32,  3.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars318.png: 192x320 1 license_plate, 33.1ms\n",
            "Speed: 1.7ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  63%|██████▎   | 217/345 [01:06<00:31,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars302.png: 160x320 2 license_plates, 28.0ms\n",
            "Speed: 0.9ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  63%|██████▎   | 218/345 [01:06<00:30,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars159.png: 288x320 2 license_plates, 43.7ms\n",
            "Speed: 1.2ms preprocess, 43.7ms inference, 0.8ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  63%|██████▎   | 219/345 [01:06<00:32,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars8.png: 160x320 1 license_plate, 29.5ms\n",
            "Speed: 0.9ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  64%|██████▍   | 220/345 [01:06<00:29,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars269.png: 256x320 1 license_plate, 38.8ms\n",
            "Speed: 1.3ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  64%|██████▍   | 221/345 [01:07<00:30,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars304.png: 192x320 1 license_plate, 29.6ms\n",
            "Speed: 1.1ms preprocess, 29.6ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  64%|██████▍   | 222/345 [01:07<00:30,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars17.png: 224x320 2 license_plates, 34.4ms\n",
            "Speed: 1.2ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  65%|██████▍   | 223/345 [01:07<00:30,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars337.png: 256x320 2 license_plates, 42.7ms\n",
            "Speed: 1.3ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  65%|██████▍   | 224/345 [01:07<00:30,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars349.png: 224x320 1 license_plate, 38.8ms\n",
            "Speed: 1.3ms preprocess, 38.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  65%|██████▌   | 225/345 [01:08<00:30,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars178.png: 256x320 1 license_plate, 35.1ms\n",
            "Speed: 1.1ms preprocess, 35.1ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  66%|██████▌   | 226/345 [01:08<00:30,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars1.png: 224x320 1 license_plate, 33.6ms\n",
            "Speed: 1.3ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  66%|██████▌   | 227/345 [01:08<00:29,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars247.png: 192x320 1 license_plate, 27.8ms\n",
            "Speed: 0.9ms preprocess, 27.8ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  66%|██████▌   | 228/345 [01:08<00:28,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars377.png: 192x320 1 license_plate, 30.4ms\n",
            "Speed: 1.3ms preprocess, 30.4ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  66%|██████▋   | 229/345 [01:09<00:28,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars243.png: 256x320 1 license_plate, 38.8ms\n",
            "Speed: 1.5ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  67%|██████▋   | 230/345 [01:09<00:31,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars196.png: 224x320 (no detections), 57.8ms\n",
            "Speed: 1.4ms preprocess, 57.8ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  67%|██████▋   | 231/345 [01:09<00:33,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars355.png: 224x320 1 license_plate, 47.5ms\n",
            "Speed: 1.2ms preprocess, 47.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  67%|██████▋   | 232/345 [01:10<00:35,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars52.png: 256x320 1 license_plate, 47.6ms\n",
            "Speed: 1.3ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  68%|██████▊   | 233/345 [01:10<00:37,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars284.png: 320x256 1 license_plate, 49.3ms\n",
            "Speed: 1.7ms preprocess, 49.3ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  68%|██████▊   | 234/345 [01:10<00:37,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars250.png: 224x320 1 license_plate, 53.8ms\n",
            "Speed: 1.1ms preprocess, 53.8ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  68%|██████▊   | 235/345 [01:11<00:37,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars184.png: 192x320 1 license_plate, 41.9ms\n",
            "Speed: 1.0ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  68%|██████▊   | 236/345 [01:11<00:36,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars312.png: 192x320 1 license_plate, 47.0ms\n",
            "Speed: 1.1ms preprocess, 47.0ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  69%|██████▊   | 237/345 [01:12<00:38,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars401.png: 256x320 1 license_plate, 51.6ms\n",
            "Speed: 1.3ms preprocess, 51.6ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  69%|██████▉   | 238/345 [01:12<00:39,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars297.png: 192x320 1 license_plate, 46.4ms\n",
            "Speed: 1.0ms preprocess, 46.4ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  69%|██████▉   | 239/345 [01:12<00:38,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars22.png: 256x320 1 license_plate, 50.1ms\n",
            "Speed: 1.2ms preprocess, 50.1ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  70%|██████▉   | 240/345 [01:13<00:37,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars213.png: 256x320 2 license_plates, 54.1ms\n",
            "Speed: 2.3ms preprocess, 54.1ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  70%|██████▉   | 241/345 [01:13<00:38,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars307.png: 224x320 1 license_plate, 57.7ms\n",
            "Speed: 1.1ms preprocess, 57.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  70%|███████   | 242/345 [01:13<00:40,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars416.png: 256x320 1 license_plate, 66.3ms\n",
            "Speed: 1.2ms preprocess, 66.3ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  70%|███████   | 243/345 [01:14<00:41,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars421.png: 256x320 1 license_plate, 68.1ms\n",
            "Speed: 1.2ms preprocess, 68.1ms inference, 5.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  71%|███████   | 244/345 [01:14<00:41,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars190.png: 256x320 1 license_plate, 52.2ms\n",
            "Speed: 1.5ms preprocess, 52.2ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  71%|███████   | 245/345 [01:15<00:41,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars107.png: 192x320 1 license_plate, 49.0ms\n",
            "Speed: 1.3ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  71%|███████▏  | 246/345 [01:15<00:39,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars360.png: 192x320 1 license_plate, 43.8ms\n",
            "Speed: 1.0ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  72%|███████▏  | 247/345 [01:15<00:37,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars128.png: 192x320 1 license_plate, 45.6ms\n",
            "Speed: 1.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  72%|███████▏  | 248/345 [01:16<00:35,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars329.png: 224x320 1 license_plate, 52.7ms\n",
            "Speed: 1.1ms preprocess, 52.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  72%|███████▏  | 249/345 [01:16<00:35,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars330.png: 256x320 (no detections), 51.4ms\n",
            "Speed: 1.2ms preprocess, 51.4ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  72%|███████▏  | 250/345 [01:17<00:36,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars231.png: 224x320 1 license_plate, 52.8ms\n",
            "Speed: 2.0ms preprocess, 52.8ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  73%|███████▎  | 251/345 [01:17<00:37,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars131.png: 192x320 3 license_plates, 54.0ms\n",
            "Speed: 1.0ms preprocess, 54.0ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  73%|███████▎  | 252/345 [01:17<00:34,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars150.png: 256x320 1 license_plate, 54.9ms\n",
            "Speed: 1.2ms preprocess, 54.9ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  73%|███████▎  | 253/345 [01:18<00:32,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars111.png: 192x320 1 license_plate, 39.4ms\n",
            "Speed: 1.1ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  74%|███████▎  | 254/345 [01:18<00:29,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars342.png: 256x320 1 license_plate, 40.5ms\n",
            "Speed: 1.4ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  74%|███████▍  | 255/345 [01:18<00:27,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars3.png: 192x320 1 license_plate, 31.5ms\n",
            "Speed: 0.9ms preprocess, 31.5ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  74%|███████▍  | 256/345 [01:18<00:25,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars376.png: 224x320 1 license_plate, 33.0ms\n",
            "Speed: 1.2ms preprocess, 33.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  74%|███████▍  | 257/345 [01:19<00:24,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars175.png: 256x320 1 license_plate, 39.8ms\n",
            "Speed: 1.3ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  75%|███████▍  | 258/345 [01:19<00:24,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars69.png: 224x320 1 license_plate, 36.0ms\n",
            "Speed: 1.2ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  75%|███████▌  | 259/345 [01:19<00:23,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars24.png: 256x320 1 license_plate, 36.5ms\n",
            "Speed: 1.4ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  75%|███████▌  | 260/345 [01:19<00:22,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars169.png: 160x320 1 license_plate, 37.4ms\n",
            "Speed: 0.9ms preprocess, 37.4ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  76%|███████▌  | 261/345 [01:20<00:22,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars161.png: 256x320 1 license_plate, 33.6ms\n",
            "Speed: 1.5ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  76%|███████▌  | 262/345 [01:20<00:22,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars233.png: 128x320 1 license_plate, 25.3ms\n",
            "Speed: 0.7ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 128, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  76%|███████▌  | 263/345 [01:20<00:19,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars375.png: 256x320 1 license_plate, 47.1ms\n",
            "Speed: 1.1ms preprocess, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  77%|███████▋  | 264/345 [01:20<00:20,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars241.png: 224x320 1 license_plate, 31.9ms\n",
            "Speed: 1.6ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  77%|███████▋  | 265/345 [01:21<00:19,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars65.png: 288x320 1 license_plate, 43.9ms\n",
            "Speed: 1.5ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  77%|███████▋  | 266/345 [01:21<00:20,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars277.png: 256x320 1 license_plate, 35.5ms\n",
            "Speed: 1.1ms preprocess, 35.5ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  77%|███████▋  | 267/345 [01:21<00:20,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars411.png: 224x320 1 license_plate, 36.3ms\n",
            "Speed: 1.2ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  78%|███████▊  | 268/345 [01:21<00:19,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars40.png: 192x320 1 license_plate, 36.8ms\n",
            "Speed: 0.9ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  78%|███████▊  | 269/345 [01:22<00:19,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars430.png: 192x320 1 license_plate, 33.3ms\n",
            "Speed: 1.0ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  78%|███████▊  | 270/345 [01:22<00:18,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars240.png: 192x320 1 license_plate, 32.9ms\n",
            "Speed: 1.3ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  79%|███████▊  | 271/345 [01:22<00:17,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars214.png: 224x320 1 license_plate, 35.2ms\n",
            "Speed: 0.8ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  79%|███████▉  | 272/345 [01:22<00:17,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars187.png: 192x320 1 license_plate, 31.9ms\n",
            "Speed: 1.2ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  79%|███████▉  | 273/345 [01:23<00:17,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars207.png: 320x288 2 license_plates, 50.2ms\n",
            "Speed: 2.1ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 288)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  79%|███████▉  | 274/345 [01:23<00:18,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars98.png: 320x320 1 license_plate, 43.0ms\n",
            "Speed: 1.6ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  80%|███████▉  | 275/345 [01:23<00:19,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars129.png: 256x320 1 license_plate, 37.8ms\n",
            "Speed: 1.3ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  80%|████████  | 276/345 [01:24<00:18,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars143.png: 224x320 2 license_plates, 37.8ms\n",
            "Speed: 1.5ms preprocess, 37.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  80%|████████  | 277/345 [01:24<00:18,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars132.png: 192x320 (no detections), 29.2ms\n",
            "Speed: 1.2ms preprocess, 29.2ms inference, 0.3ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  81%|████████  | 278/345 [01:24<00:17,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars356.png: 224x320 1 license_plate, 33.6ms\n",
            "Speed: 1.0ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  81%|████████  | 279/345 [01:24<00:17,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars219.png: 256x320 1 license_plate, 44.7ms\n",
            "Speed: 1.6ms preprocess, 44.7ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  81%|████████  | 280/345 [01:25<00:17,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars397.png: 256x320 2 license_plates, 36.7ms\n",
            "Speed: 1.3ms preprocess, 36.7ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  81%|████████▏ | 281/345 [01:25<00:17,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars254.png: 320x320 1 license_plate, 39.9ms\n",
            "Speed: 1.6ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  82%|████████▏ | 282/345 [01:25<00:17,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars83.png: 256x320 1 license_plate, 32.8ms\n",
            "Speed: 1.6ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  82%|████████▏ | 283/345 [01:25<00:17,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars165.png: 192x320 2 license_plates, 30.7ms\n",
            "Speed: 1.2ms preprocess, 30.7ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  82%|████████▏ | 284/345 [01:26<00:17,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars116.png: 288x320 1 license_plate, 69.1ms\n",
            "Speed: 1.4ms preprocess, 69.1ms inference, 0.8ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  83%|████████▎ | 285/345 [01:26<00:17,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars229.png: 192x320 (no detections), 30.5ms\n",
            "Speed: 0.9ms preprocess, 30.5ms inference, 0.4ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  83%|████████▎ | 286/345 [01:26<00:15,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars141.png: 224x320 1 license_plate, 33.7ms\n",
            "Speed: 1.0ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  83%|████████▎ | 287/345 [01:27<00:15,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars185.png: 224x320 1 license_plate, 38.4ms\n",
            "Speed: 1.0ms preprocess, 38.4ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  83%|████████▎ | 288/345 [01:27<00:14,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars173.png: 192x320 1 license_plate, 28.8ms\n",
            "Speed: 0.9ms preprocess, 28.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  84%|████████▍ | 289/345 [01:27<00:14,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars389.png: 256x320 1 license_plate, 37.2ms\n",
            "Speed: 1.3ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  84%|████████▍ | 290/345 [01:27<00:14,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars331.png: 256x320 1 license_plate, 36.5ms\n",
            "Speed: 1.4ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  84%|████████▍ | 291/345 [01:28<00:15,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars211.png: 256x320 1 license_plate, 60.0ms\n",
            "Speed: 1.1ms preprocess, 60.0ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  85%|████████▍ | 292/345 [01:28<00:16,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars100.png: 224x320 1 license_plate, 61.8ms\n",
            "Speed: 1.2ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  85%|████████▍ | 293/345 [01:28<00:18,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars12.png: 128x320 1 license_plate, 33.3ms\n",
            "Speed: 0.7ms preprocess, 33.3ms inference, 0.8ms postprocess per image at shape (1, 3, 128, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  85%|████████▌ | 294/345 [01:29<00:15,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars56.png: 160x320 1 license_plate, 60.5ms\n",
            "Speed: 0.8ms preprocess, 60.5ms inference, 0.9ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  86%|████████▌ | 295/345 [01:29<00:15,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars43.png: 192x320 1 license_plate, 48.1ms\n",
            "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  86%|████████▌ | 296/345 [01:29<00:15,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars384.png: 256x320 1 license_plate, 64.3ms\n",
            "Speed: 1.2ms preprocess, 64.3ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  86%|████████▌ | 297/345 [01:30<00:16,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars47.png: 256x320 1 license_plate, 60.7ms\n",
            "Speed: 1.2ms preprocess, 60.7ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  86%|████████▋ | 298/345 [01:30<00:16,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars68.png: 224x320 1 license_plate, 41.7ms\n",
            "Speed: 1.4ms preprocess, 41.7ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  87%|████████▋ | 299/345 [01:30<00:16,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars263.png: 256x320 1 license_plate, 61.5ms\n",
            "Speed: 1.2ms preprocess, 61.5ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  87%|████████▋ | 300/345 [01:31<00:16,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars20.png: 224x320 1 license_plate, 54.0ms\n",
            "Speed: 1.0ms preprocess, 54.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  87%|████████▋ | 301/345 [01:32<00:25,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars158.png: 256x320 1 license_plate, 52.7ms\n",
            "Speed: 1.4ms preprocess, 52.7ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  88%|████████▊ | 302/345 [01:32<00:22,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars396.png: 320x256 1 license_plate, 56.1ms\n",
            "Speed: 1.2ms preprocess, 56.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  88%|████████▊ | 303/345 [01:33<00:20,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars372.png: 256x320 1 license_plate, 60.2ms\n",
            "Speed: 1.4ms preprocess, 60.2ms inference, 0.9ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  88%|████████▊ | 304/345 [01:33<00:19,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars259.png: 192x320 1 license_plate, 58.1ms\n",
            "Speed: 1.0ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  88%|████████▊ | 305/345 [01:33<00:17,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars28.png: 256x320 (no detections), 67.1ms\n",
            "Speed: 1.3ms preprocess, 67.1ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  89%|████████▊ | 306/345 [01:34<00:17,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars5.png: 256x320 1 license_plate, 53.7ms\n",
            "Speed: 1.1ms preprocess, 53.7ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  89%|████████▉ | 307/345 [01:34<00:16,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars419.png: 288x320 1 license_plate, 61.9ms\n",
            "Speed: 1.3ms preprocess, 61.9ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  89%|████████▉ | 308/345 [01:35<00:16,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars67.png: 160x320 1 license_plate, 43.5ms\n",
            "Speed: 0.9ms preprocess, 43.5ms inference, 0.9ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  90%|████████▉ | 309/345 [01:35<00:14,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars365.png: 224x320 1 license_plate, 50.3ms\n",
            "Speed: 1.5ms preprocess, 50.3ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  90%|████████▉ | 310/345 [01:36<00:14,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars270.png: 192x320 1 license_plate, 53.7ms\n",
            "Speed: 0.9ms preprocess, 53.7ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  90%|█████████ | 311/345 [01:36<00:13,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars228.png: 160x320 1 license_plate, 41.4ms\n",
            "Speed: 0.8ms preprocess, 41.4ms inference, 0.8ms postprocess per image at shape (1, 3, 160, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  90%|█████████ | 312/345 [01:36<00:11,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars144.png: 288x320 1 license_plate, 59.5ms\n",
            "Speed: 0.8ms preprocess, 59.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  91%|█████████ | 313/345 [01:37<00:12,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars374.png: 192x320 1 license_plate, 34.9ms\n",
            "Speed: 1.1ms preprocess, 34.9ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  91%|█████████ | 314/345 [01:37<00:10,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars271.png: 224x320 1 license_plate, 39.2ms\n",
            "Speed: 1.3ms preprocess, 39.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  91%|█████████▏| 315/345 [01:37<00:09,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars306.png: 320x320 1 license_plate, 43.2ms\n",
            "Speed: 1.3ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  92%|█████████▏| 316/345 [01:37<00:09,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars399.png: 192x320 1 license_plate, 31.2ms\n",
            "Speed: 1.3ms preprocess, 31.2ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  92%|█████████▏| 317/345 [01:38<00:08,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars324.png: 192x320 1 license_plate, 35.9ms\n",
            "Speed: 1.7ms preprocess, 35.9ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  92%|█████████▏| 318/345 [01:38<00:07,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars25.png: 192x320 1 license_plate, 37.0ms\n",
            "Speed: 1.5ms preprocess, 37.0ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  92%|█████████▏| 319/345 [01:38<00:07,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars201.png: 192x320 1 license_plate, 25.8ms\n",
            "Speed: 0.8ms preprocess, 25.8ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  93%|█████████▎| 320/345 [01:38<00:06,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars96.png: 224x320 1 license_plate, 51.9ms\n",
            "Speed: 1.0ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  93%|█████████▎| 321/345 [01:39<00:06,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars200.png: 224x320 1 license_plate, 42.4ms\n",
            "Speed: 2.4ms preprocess, 42.4ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  93%|█████████▎| 322/345 [01:39<00:06,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars245.png: 224x320 1 license_plate, 33.9ms\n",
            "Speed: 1.3ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  94%|█████████▎| 323/345 [01:39<00:05,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars14.png: 192x320 1 license_plate, 31.5ms\n",
            "Speed: 0.9ms preprocess, 31.5ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  94%|█████████▍| 324/345 [01:39<00:05,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars134.png: 224x320 1 license_plate, 48.1ms\n",
            "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  94%|█████████▍| 325/345 [01:40<00:05,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars206.png: 256x320 1 license_plate, 38.2ms\n",
            "Speed: 1.3ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  94%|█████████▍| 326/345 [01:40<00:04,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars423.png: 224x320 1 license_plate, 35.7ms\n",
            "Speed: 1.2ms preprocess, 35.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  95%|█████████▍| 327/345 [01:40<00:04,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars89.png: 224x320 1 license_plate, 34.7ms\n",
            "Speed: 1.0ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  95%|█████████▌| 328/345 [01:40<00:04,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars370.png: 224x320 1 license_plate, 42.1ms\n",
            "Speed: 1.1ms preprocess, 42.1ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  95%|█████████▌| 329/345 [01:41<00:04,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars163.png: 192x320 1 license_plate, 29.6ms\n",
            "Speed: 1.0ms preprocess, 29.6ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  96%|█████████▌| 330/345 [01:41<00:03,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars235.png: 192x320 1 license_plate, 31.3ms\n",
            "Speed: 1.1ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  96%|█████████▌| 331/345 [01:41<00:03,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars109.png: 224x320 1 license_plate, 35.7ms\n",
            "Speed: 1.0ms preprocess, 35.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  96%|█████████▌| 332/345 [01:41<00:03,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars130.png: 224x320 1 license_plate, 34.9ms\n",
            "Speed: 1.0ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  97%|█████████▋| 333/345 [01:42<00:03,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars114.png: 192x320 3 license_plates, 28.5ms\n",
            "Speed: 1.5ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  97%|█████████▋| 334/345 [01:42<00:02,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars91.png: 224x320 1 license_plate, 37.2ms\n",
            "Speed: 1.0ms preprocess, 37.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  97%|█████████▋| 335/345 [01:42<00:02,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars417.png: 256x320 1 license_plate, 33.9ms\n",
            "Speed: 1.3ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  97%|█████████▋| 336/345 [01:42<00:02,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars36.png: 256x320 1 license_plate, 39.0ms\n",
            "Speed: 1.2ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  98%|█████████▊| 337/345 [01:43<00:02,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars102.png: 256x320 1 license_plate, 37.6ms\n",
            "Speed: 1.9ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  98%|█████████▊| 338/345 [01:43<00:01,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars368.png: 256x320 1 license_plate, 42.4ms\n",
            "Speed: 1.1ms preprocess, 42.4ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  98%|█████████▊| 339/345 [01:43<00:01,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars86.png: 192x320 1 license_plate, 29.7ms\n",
            "Speed: 0.9ms preprocess, 29.7ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  99%|█████████▊| 340/345 [01:44<00:01,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars110.png: 224x320 1 license_plate, 37.9ms\n",
            "Speed: 1.0ms preprocess, 37.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  99%|█████████▉| 341/345 [01:44<00:01,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars255.png: 224x320 1 license_plate, 35.6ms\n",
            "Speed: 1.3ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  99%|█████████▉| 342/345 [01:44<00:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars292.png: 224x320 1 license_plate, 36.9ms\n",
            "Speed: 1.1ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:  99%|█████████▉| 343/345 [01:44<00:00,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars54.png: 256x320 1 license_plate, 38.5ms\n",
            "Speed: 1.4ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 256, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images: 100%|█████████▉| 344/345 [01:45<00:00,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset/preprocessed_images/Cars199.png: 224x320 1 license_plate, 37.6ms\n",
            "Speed: 1.3ms preprocess, 37.6ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 345/345 [01:45<00:00,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection Summary:\n",
            "Total images processed: 345\n",
            "Images with detections: 329\n",
            "Total license plates detected: 357\n",
            "Average confidence score: 72.78%\n",
            "\n",
            "Predictions saved in 'predictions' directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cars124.png': {'detections': [{'bbox': [178, 230, 201, 240],\n",
              "    'confidence': 0.36244356632232666}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars124.png'},\n",
              " 'Cars315.png': {'detections': [{'bbox': [32, 100, 391, 179],\n",
              "    'confidence': 0.7551630139350891}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars315.png'},\n",
              " 'Cars282.png': {'detections': [{'bbox': [60, 144, 324, 201],\n",
              "    'confidence': 0.8149523735046387}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars282.png'},\n",
              " 'Cars236.png': {'detections': [{'bbox': [221, 107, 251, 116],\n",
              "    'confidence': 0.6304125785827637}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars236.png'},\n",
              " 'Cars112.png': {'detections': [{'bbox': [50, 136, 162, 181],\n",
              "    'confidence': 0.8596819639205933}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars112.png'},\n",
              " 'Cars402.png': {'detections': [{'bbox': [361, 164, 437, 182],\n",
              "    'confidence': 0.7737888693809509}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars402.png'},\n",
              " 'Cars105.png': {'detections': [{'bbox': [153, 145, 206, 158],\n",
              "    'confidence': 0.4375939667224884},\n",
              "   {'bbox': [155, 167, 201, 182], 'confidence': 0.2854117155075073}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars105.png'},\n",
              " 'Cars358.png': {'detections': [{'bbox': [44, 94, 107, 106],\n",
              "    'confidence': 0.689913272857666},\n",
              "   {'bbox': [295, 120, 359, 135], 'confidence': 0.6686893701553345}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars358.png'},\n",
              " 'Cars180.png': {'detections': [{'bbox': [148, 112, 304, 178],\n",
              "    'confidence': 0.8779211044311523}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars180.png'},\n",
              " 'Cars280.png': {'detections': [{'bbox': [188, 183, 215, 195],\n",
              "    'confidence': 0.6853410005569458}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars280.png'},\n",
              " 'Cars265.png': {'detections': [{'bbox': [94, 170, 211, 206],\n",
              "    'confidence': 0.8020449280738831}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars265.png'},\n",
              " 'Cars230.png': {'detections': [{'bbox': [220, 172, 359, 202],\n",
              "    'confidence': 0.7657414078712463}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars230.png'},\n",
              " 'Cars386.png': {'detections': [{'bbox': [81, 303, 222, 368],\n",
              "    'confidence': 0.8210427165031433}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars386.png'},\n",
              " 'Cars275.png': {'detections': [{'bbox': [98, 149, 161, 167],\n",
              "    'confidence': 0.7337735891342163}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars275.png'},\n",
              " 'Cars424.png': {'detections': [{'bbox': [129, 171, 463, 237],\n",
              "    'confidence': 0.8129261136054993}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars424.png'},\n",
              " 'Cars11.png': {'detections': [{'bbox': [121, 200, 280, 235],\n",
              "    'confidence': 0.8087774515151978}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars11.png'},\n",
              " 'Cars390.png': {'detections': [{'bbox': [7, 141, 47, 163],\n",
              "    'confidence': 0.7339373826980591}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars390.png'},\n",
              " 'Cars51.png': {'detections': [{'bbox': [265, 140, 318, 162],\n",
              "    'confidence': 0.7826051712036133}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars51.png'},\n",
              " 'Cars309.png': {'detections': [{'bbox': [156, 123, 255, 210],\n",
              "    'confidence': 0.8092548847198486}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars309.png'},\n",
              " 'Cars226.png': {'detections': [{'bbox': [250, 194, 317, 211],\n",
              "    'confidence': 0.7536547780036926}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars226.png'},\n",
              " 'Cars273.png': {'detections': [{'bbox': [80, 132, 254, 170],\n",
              "    'confidence': 0.7953636646270752}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars273.png'},\n",
              " 'Cars380.png': {'detections': [{'bbox': [317, 92, 364, 124],\n",
              "    'confidence': 0.709839940071106}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars380.png'},\n",
              " 'Cars31.png': {'detections': [{'bbox': [285, 174, 400, 209],\n",
              "    'confidence': 0.8519687056541443}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars31.png'},\n",
              " 'Cars418.png': {'detections': [{'bbox': [103, 67, 304, 159],\n",
              "    'confidence': 0.8670428395271301}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars418.png'},\n",
              " 'Cars257.png': {'detections': [{'bbox': [166, 130, 240, 167],\n",
              "    'confidence': 0.8762091994285583}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars257.png'},\n",
              " 'Cars92.png': {'detections': [{'bbox': [277, 186, 396, 271],\n",
              "    'confidence': 0.896625816822052}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars92.png'},\n",
              " 'Cars344.png': {'detections': [{'bbox': [235, 158, 380, 218],\n",
              "    'confidence': 0.8481213450431824}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars344.png'},\n",
              " 'Cars26.png': {'detections': [{'bbox': [260, 184, 317, 213],\n",
              "    'confidence': 0.76183021068573}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars26.png'},\n",
              " 'Cars157.png': {'detections': [{'bbox': [330, 155, 367, 179],\n",
              "    'confidence': 0.546715497970581},\n",
              "   {'bbox': [325, 154, 367, 188], 'confidence': 0.2613453269004822}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars157.png'},\n",
              " 'Cars76.png': {'detections': [{'bbox': [23, 114, 469, 231],\n",
              "    'confidence': 0.8296851515769958}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars76.png'},\n",
              " 'Cars79.png': {'detections': [{'bbox': [239, 365, 347, 420],\n",
              "    'confidence': 0.8431838750839233}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars79.png'},\n",
              " 'Cars427.png': {'detections': [{'bbox': [237, 192, 370, 226],\n",
              "    'confidence': 0.7775614261627197}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars427.png'},\n",
              " 'Cars74.png': {'detections': [{'bbox': [115, 115, 277, 152],\n",
              "    'confidence': 0.8681740164756775}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars74.png'},\n",
              " 'Cars41.png': {'detections': [{'bbox': [109, 181, 159, 206],\n",
              "    'confidence': 0.8375182747840881}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars41.png'},\n",
              " 'Cars310.png': {'detections': [{'bbox': [239, 365, 347, 420],\n",
              "    'confidence': 0.8431838750839233}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars310.png'},\n",
              " 'Cars242.png': {'detections': [{'bbox': [228, 172, 268, 195],\n",
              "    'confidence': 0.7725644707679749}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars242.png'},\n",
              " 'Cars406.png': {'detections': [{'bbox': [286, 184, 373, 222],\n",
              "    'confidence': 0.7053740620613098}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars406.png'},\n",
              " 'Cars145.png': {'detections': [{'bbox': [284, 248, 422, 278],\n",
              "    'confidence': 0.8287874460220337}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars145.png'},\n",
              " 'Cars189.png': {'detections': [{'bbox': [284, 248, 422, 278],\n",
              "    'confidence': 0.8287874460220337}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars189.png'},\n",
              " 'Cars291.png': {'detections': [{'bbox': [96, 188, 167, 200],\n",
              "    'confidence': 0.2770633101463318}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars291.png'},\n",
              " 'Cars176.png': {'detections': [{'bbox': [70, 76, 309, 188],\n",
              "    'confidence': 0.8823809623718262}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars176.png'},\n",
              " 'Cars232.png': {'detections': [{'bbox': [173, 173, 227, 202],\n",
              "    'confidence': 0.8406460881233215}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars232.png'},\n",
              " 'Cars381.png': {'detections': [{'bbox': [65, 132, 146, 155],\n",
              "    'confidence': 0.8006871342658997}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars381.png'},\n",
              " 'Cars222.png': {'detections': [{'bbox': [177, 154, 235, 170],\n",
              "    'confidence': 0.7423731088638306}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars222.png'},\n",
              " 'Cars44.png': {'detections': [{'bbox': [19, 157, 436, 277],\n",
              "    'confidence': 0.8388636708259583}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars44.png'},\n",
              " 'Cars313.png': {'detections': [{'bbox': [176, 209, 250, 245],\n",
              "    'confidence': 0.8509823679924011}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars313.png'},\n",
              " 'Cars296.png': {'detections': [{'bbox': [161, 158, 234, 195],\n",
              "    'confidence': 0.8541791439056396}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars296.png'},\n",
              " 'Cars303.png': {'detections': [{'bbox': [152, 212, 248, 236],\n",
              "    'confidence': 0.7554317712783813}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars303.png'},\n",
              " 'Cars301.png': {'detections': [{'bbox': [206, 103, 303, 135],\n",
              "    'confidence': 0.8052502870559692}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars301.png'},\n",
              " 'Cars379.png': {'detections': [{'bbox': [198, 197, 350, 241],\n",
              "    'confidence': 0.8762956857681274}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars379.png'},\n",
              " 'Cars350.png': {'detections': [{'bbox': [163, 178, 208, 188],\n",
              "    'confidence': 0.4980422854423523}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars350.png'},\n",
              " 'Cars361.png': {'detections': [{'bbox': [148, 112, 304, 178],\n",
              "    'confidence': 0.8779211044311523}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars361.png'},\n",
              " 'Cars137.png': {'detections': [{'bbox': [173, 182, 204, 191],\n",
              "    'confidence': 0.4809492528438568}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars137.png'},\n",
              " 'Cars248.png': {'detections': [{'bbox': [185, 142, 307, 188],\n",
              "    'confidence': 0.822524905204773}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars248.png'},\n",
              " 'Cars239.png': {'detections': [{'bbox': [178, 253, 328, 284],\n",
              "    'confidence': 0.8312525153160095}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars239.png'},\n",
              " 'Cars90.png': {'detections': [{'bbox': [77, 204, 98, 222],\n",
              "    'confidence': 0.7196475863456726}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars90.png'},\n",
              " 'Cars256.png': {'detections': [{'bbox': [285, 174, 400, 209],\n",
              "    'confidence': 0.8519687056541443}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars256.png'},\n",
              " 'Cars359.png': {'detections': [{'bbox': [228, 227, 265, 239],\n",
              "    'confidence': 0.6365097761154175}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars359.png'},\n",
              " 'Cars88.png': {'detections': [{'bbox': [169, 148, 242, 171],\n",
              "    'confidence': 0.7812920808792114}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars88.png'},\n",
              " 'Cars205.png': {'detections': [{'bbox': [152, 163, 219, 197],\n",
              "    'confidence': 0.8308253288269043},\n",
              "   {'bbox': [310, 389, 399, 400], 'confidence': 0.5469701886177063}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars205.png'},\n",
              " 'Cars314.png': {'detections': [{'bbox': [194, 151, 276, 209],\n",
              "    'confidence': 0.7926523685455322}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars314.png'},\n",
              " 'Cars162.png': {'detections': [{'bbox': [243, 188, 265, 206],\n",
              "    'confidence': 0.3053959608078003}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars162.png'},\n",
              " 'Cars99.png': {'detections': [{'bbox': [70, 198, 261, 269],\n",
              "    'confidence': 0.8398513793945312}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars99.png'},\n",
              " 'Cars64.png': {'detections': [{'bbox': [123, 187, 329, 222],\n",
              "    'confidence': 0.7366328835487366}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars64.png'},\n",
              " 'Cars16.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars16.png'},\n",
              " 'Cars7.png': {'detections': [{'bbox': [168, 141, 205, 154],\n",
              "    'confidence': 0.7347596287727356}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars7.png'},\n",
              " 'Cars191.png': {'detections': [{'bbox': [92, 185, 199, 218],\n",
              "    'confidence': 0.7708680033683777}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars191.png'},\n",
              " 'Cars6.png': {'detections': [{'bbox': [111, 113, 374, 238],\n",
              "    'confidence': 0.8877485990524292}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars6.png'},\n",
              " 'Cars142.png': {'detections': [{'bbox': [176, 122, 269, 145],\n",
              "    'confidence': 0.7648544907569885}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars142.png'},\n",
              " 'Cars179.png': {'detections': [{'bbox': [65, 169, 130, 194],\n",
              "    'confidence': 0.4587223529815674}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars179.png'},\n",
              " 'Cars209.png': {'detections': [{'bbox': [358, 170, 386, 184],\n",
              "    'confidence': 0.7377415299415588}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars209.png'},\n",
              " 'Cars285.png': {'detections': [{'bbox': [89, 111, 164, 132],\n",
              "    'confidence': 0.7137470841407776}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars285.png'},\n",
              " 'Cars300.png': {'detections': [{'bbox': [260, 184, 317, 213],\n",
              "    'confidence': 0.76183021068573}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars300.png'},\n",
              " 'Cars153.png': {'detections': [{'bbox': [141, 114, 315, 163],\n",
              "    'confidence': 0.8270980715751648}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars153.png'},\n",
              " 'Cars121.png': {'detections': [{'bbox': [334, 191, 361, 200],\n",
              "    'confidence': 0.6498197317123413}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars121.png'},\n",
              " 'Cars166.png': {'detections': [{'bbox': [146, 127, 203, 156],\n",
              "    'confidence': 0.6415719389915466}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars166.png'},\n",
              " 'Cars61.png': {'detections': [{'bbox': [73, 124, 198, 230],\n",
              "    'confidence': 0.875158429145813}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars61.png'},\n",
              " 'Cars62.png': {'detections': [{'bbox': [156, 108, 242, 158],\n",
              "    'confidence': 0.8555480241775513}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars62.png'},\n",
              " 'Cars252.png': {'detections': [{'bbox': [173, 239, 318, 271],\n",
              "    'confidence': 0.8270537853240967}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars252.png'},\n",
              " 'Cars227.png': {'detections': [{'bbox': [121, 178, 154, 195],\n",
              "    'confidence': 0.5677785277366638},\n",
              "   {'bbox': [122, 196, 163, 211], 'confidence': 0.30884990096092224},\n",
              "   {'bbox': [120, 195, 159, 209], 'confidence': 0.2885567247867584}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars227.png'},\n",
              " 'Cars202.png': {'detections': [{'bbox': [197, 136, 246, 155],\n",
              "    'confidence': 0.8263440728187561}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars202.png'},\n",
              " 'Cars422.png': {'detections': [{'bbox': [159, 126, 292, 178],\n",
              "    'confidence': 0.7534291744232178}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars422.png'},\n",
              " 'Cars71.png': {'detections': [{'bbox': [255, 143, 282, 152],\n",
              "    'confidence': 0.647463858127594}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars71.png'},\n",
              " 'Cars81.png': {'detections': [{'bbox': [296, 101, 329, 125],\n",
              "    'confidence': 0.8007957935333252}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars81.png'},\n",
              " 'Cars133.png': {'detections': [{'bbox': [286, 184, 373, 222],\n",
              "    'confidence': 0.7053740620613098}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars133.png'},\n",
              " 'Cars170.png': {'detections': [{'bbox': [312, 195, 348, 223],\n",
              "    'confidence': 0.7654531002044678}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars170.png'},\n",
              " 'Cars333.png': {'detections': [{'bbox': [114, 156, 272, 190],\n",
              "    'confidence': 0.8438668847084045}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars333.png'},\n",
              " 'Cars138.png': {'detections': [{'bbox': [150, 141, 256, 188],\n",
              "    'confidence': 0.7352755069732666},\n",
              "   {'bbox': [152, 141, 256, 169], 'confidence': 0.5962165594100952}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars138.png'},\n",
              " 'Cars410.png': {'detections': [{'bbox': [51, 150, 218, 211],\n",
              "    'confidence': 0.8772885203361511}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars410.png'},\n",
              " 'Cars10.png': {'detections': [{'bbox': [146, 25, 298, 147],\n",
              "    'confidence': 0.8350075483322144}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars10.png'},\n",
              " 'Cars238.png': {'detections': [{'bbox': [277, 186, 396, 271],\n",
              "    'confidence': 0.896625816822052}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars238.png'},\n",
              " 'Cars216.png': {'detections': [{'bbox': [205, 219, 283, 265],\n",
              "    'confidence': 0.7429083585739136}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars216.png'},\n",
              " 'Cars94.png': {'detections': [{'bbox': [176, 209, 250, 245],\n",
              "    'confidence': 0.8509823679924011}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars94.png'},\n",
              " 'Cars288.png': {'detections': [{'bbox': [98, 149, 161, 167],\n",
              "    'confidence': 0.7337735891342163}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars288.png'},\n",
              " 'Cars149.png': {'detections': [{'bbox': [211, 184, 243, 201],\n",
              "    'confidence': 0.5341914296150208}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars149.png'},\n",
              " 'Cars212.png': {'detections': [{'bbox': [106, 101, 294, 141],\n",
              "    'confidence': 0.7837717533111572}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars212.png'},\n",
              " 'Cars188.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars188.png'},\n",
              " 'Cars383.png': {'detections': [{'bbox': [53, 215, 86, 227],\n",
              "    'confidence': 0.6207621097564697},\n",
              "   {'bbox': [52, 217, 88, 229], 'confidence': 0.32511162757873535}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars383.png'},\n",
              " 'Cars119.png': {'detections': [{'bbox': [0, 134, 23, 143],\n",
              "    'confidence': 0.42382684350013733}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars119.png'},\n",
              " 'Cars123.png': {'detections': [{'bbox': [159, 222, 236, 241],\n",
              "    'confidence': 0.7552739381790161}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars123.png'},\n",
              " 'Cars426.png': {'detections': [{'bbox': [149, 205, 283, 238],\n",
              "    'confidence': 0.8304072618484497}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars426.png'},\n",
              " 'Cars15.png': {'detections': [{'bbox': [312, 145, 367, 172],\n",
              "    'confidence': 0.7645246982574463}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars15.png'},\n",
              " 'Cars251.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars251.png'},\n",
              " 'Cars371.png': {'detections': [{'bbox': [313, 136, 371, 150],\n",
              "    'confidence': 0.7434110045433044}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars371.png'},\n",
              " 'Cars19.png': {'detections': [{'bbox': [148, 195, 219, 226],\n",
              "    'confidence': 0.7072842717170715}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars19.png'},\n",
              " 'Cars385.png': {'detections': [{'bbox': [70, 76, 309, 188],\n",
              "    'confidence': 0.8823809623718262}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars385.png'},\n",
              " 'Cars327.png': {'detections': [{'bbox': [135, 125, 259, 161],\n",
              "    'confidence': 0.8512176871299744}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars327.png'},\n",
              " 'Cars394.png': {'detections': [{'bbox': [291, 167, 411, 190],\n",
              "    'confidence': 0.727778434753418}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars394.png'},\n",
              " 'Cars217.png': {'detections': [{'bbox': [148, 195, 219, 226],\n",
              "    'confidence': 0.7072842717170715}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars217.png'},\n",
              " 'Cars322.png': {'detections': [{'bbox': [270, 258, 356, 295],\n",
              "    'confidence': 0.7315905094146729}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars322.png'},\n",
              " 'Cars367.png': {'detections': [{'bbox': [235, 158, 380, 218],\n",
              "    'confidence': 0.8481213450431824}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars367.png'},\n",
              " 'Cars197.png': {'detections': [{'bbox': [220, 172, 359, 202],\n",
              "    'confidence': 0.7657414078712463}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars197.png'},\n",
              " 'Cars276.png': {'detections': [{'bbox': [115, 115, 277, 152],\n",
              "    'confidence': 0.8681740164756775}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars276.png'},\n",
              " 'Cars378.png': {'detections': [{'bbox': [116, 92, 254, 137],\n",
              "    'confidence': 0.8555179834365845}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars378.png'},\n",
              " 'Cars420.png': {'detections': [{'bbox': [111, 185, 160, 209],\n",
              "    'confidence': 0.7971933484077454}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars420.png'},\n",
              " 'Cars125.png': {'detections': [{'bbox': [279, 196, 357, 257],\n",
              "    'confidence': 0.8495442271232605}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars125.png'},\n",
              " 'Cars347.png': {'detections': [{'bbox': [226, 123, 242, 132],\n",
              "    'confidence': 0.4079693555831909}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars347.png'},\n",
              " 'Cars136.png': {'detections': [{'bbox': [164, 100, 246, 121],\n",
              "    'confidence': 0.8070272207260132}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars136.png'},\n",
              " 'Cars311.png': {'detections': [{'bbox': [297, 162, 349, 185],\n",
              "    'confidence': 0.7648111581802368}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars311.png'},\n",
              " 'Cars117.png': {'detections': [{'bbox': [45, 123, 80, 138],\n",
              "    'confidence': 0.7300088405609131}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars117.png'},\n",
              " 'Cars317.png': {'detections': [{'bbox': [164, 201, 241, 219],\n",
              "    'confidence': 0.7405029535293579}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars317.png'},\n",
              " 'Cars218.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars218.png'},\n",
              " 'Cars167.png': {'detections': [{'bbox': [178, 253, 328, 284],\n",
              "    'confidence': 0.8312525153160095}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars167.png'},\n",
              " 'Cars156.png': {'detections': [{'bbox': [113, 74, 229, 101],\n",
              "    'confidence': 0.7517739534378052}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars156.png'},\n",
              " 'Cars338.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars338.png'},\n",
              " 'Cars80.png': {'detections': [{'bbox': [93, 146, 279, 187],\n",
              "    'confidence': 0.7495313286781311}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars80.png'},\n",
              " 'Cars210.png': {'detections': [{'bbox': [56, 90, 307, 155],\n",
              "    'confidence': 0.8027385473251343}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars210.png'},\n",
              " 'Cars249.png': {'detections': [{'bbox': [299, 208, 351, 221],\n",
              "    'confidence': 0.4834180176258087},\n",
              "   {'bbox': [112, 90, 155, 103], 'confidence': 0.3741419315338135}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars249.png'},\n",
              " 'Cars382.png': {'detections': [{'bbox': [149, 205, 283, 238],\n",
              "    'confidence': 0.8304072618484497}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars382.png'},\n",
              " 'Cars407.png': {'detections': [{'bbox': [312, 183, 343, 201],\n",
              "    'confidence': 0.7130447030067444}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars407.png'},\n",
              " 'Cars139.png': {'detections': [{'bbox': [193, 222, 224, 231],\n",
              "    'confidence': 0.29611340165138245}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars139.png'},\n",
              " 'Cars60.png': {'detections': [{'bbox': [41, 97, 368, 156],\n",
              "    'confidence': 0.833116352558136}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars60.png'},\n",
              " 'Cars413.png': {'detections': [{'bbox': [238, 144, 270, 162],\n",
              "    'confidence': 0.7344744205474854}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars413.png'},\n",
              " 'Cars339.png': {'detections': [{'bbox': [213, 136, 282, 169],\n",
              "    'confidence': 0.8459362387657166}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars339.png'},\n",
              " 'Cars266.png': {'detections': [{'bbox': [9, 57, 88, 74],\n",
              "    'confidence': 0.7011664509773254}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars266.png'},\n",
              " 'Cars308.png': {'detections': [{'bbox': [159, 222, 236, 241],\n",
              "    'confidence': 0.7552739381790161}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars308.png'},\n",
              " 'Cars115.png': {'detections': [{'bbox': [312, 286, 405, 312],\n",
              "    'confidence': 0.7749935984611511}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars115.png'},\n",
              " 'Cars290.png': {'detections': [{'bbox': [211, 191, 253, 216],\n",
              "    'confidence': 0.5746012926101685},\n",
              "   {'bbox': [222, 85, 273, 120], 'confidence': 0.4920690357685089}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars290.png'},\n",
              " 'Cars388.png': {'detections': [{'bbox': [154, 130, 254, 157],\n",
              "    'confidence': 0.7927163243293762}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars388.png'},\n",
              " 'Cars267.png': {'detections': [{'bbox': [276, 118, 343, 136],\n",
              "    'confidence': 0.7352335453033447}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars267.png'},\n",
              " 'Cars118.png': {'detections': [{'bbox': [197, 164, 392, 208],\n",
              "    'confidence': 0.8208732604980469}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars118.png'},\n",
              " 'Cars34.png': {'detections': [{'bbox': [149, 180, 261, 207],\n",
              "    'confidence': 0.7891697883605957},\n",
              "   {'bbox': [390, 0, 400, 17], 'confidence': 0.26812705397605896}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars34.png'},\n",
              " 'Cars183.png': {'detections': [{'bbox': [80, 132, 254, 170],\n",
              "    'confidence': 0.7953636646270752}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars183.png'},\n",
              " 'Cars343.png': {'detections': [{'bbox': [111, 185, 160, 209],\n",
              "    'confidence': 0.7971933484077454}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars343.png'},\n",
              " 'Cars373.png': {'detections': [{'bbox': [163, 132, 265, 158],\n",
              "    'confidence': 0.7459656000137329}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars373.png'},\n",
              " 'Cars95.png': {'detections': [{'bbox': [277, 186, 396, 271],\n",
              "    'confidence': 0.896625816822052}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars95.png'},\n",
              " 'Cars293.png': {'detections': [{'bbox': [70, 162, 132, 179],\n",
              "    'confidence': 0.8368828892707825}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars293.png'},\n",
              " 'Cars146.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars146.png'},\n",
              " 'Cars283.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars283.png'},\n",
              " 'Cars32.png': {'detections': [{'bbox': [197, 148, 251, 168],\n",
              "    'confidence': 0.7586898803710938}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars32.png'},\n",
              " 'Cars38.png': {'detections': [{'bbox': [167, 196, 236, 229],\n",
              "    'confidence': 0.8075559735298157}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars38.png'},\n",
              " 'Cars328.png': {'detections': [{'bbox': [157, 148, 246, 170],\n",
              "    'confidence': 0.7878599762916565}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars328.png'},\n",
              " 'Cars193.png': {'detections': [{'bbox': [302, 192, 341, 215],\n",
              "    'confidence': 0.641828179359436}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars193.png'},\n",
              " 'Cars57.png': {'detections': [{'bbox': [270, 163, 321, 192],\n",
              "    'confidence': 0.8020040392875671}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars57.png'},\n",
              " 'Cars278.png': {'detections': [{'bbox': [279, 137, 312, 164],\n",
              "    'confidence': 0.7172161936759949}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars278.png'},\n",
              " 'Cars4.png': {'detections': [{'bbox': [151, 79, 511, 252],\n",
              "    'confidence': 0.8444080352783203}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars4.png'},\n",
              " 'Cars261.png': {'detections': [{'bbox': [17, 75, 470, 154],\n",
              "    'confidence': 0.6925790905952454},\n",
              "   {'bbox': [0, 104, 51, 145], 'confidence': 0.491527795791626}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars261.png'},\n",
              " 'Cars387.png': {'detections': [{'bbox': [163, 188, 258, 216],\n",
              "    'confidence': 0.7125011086463928}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars387.png'},\n",
              " 'Cars325.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars325.png'},\n",
              " 'Cars393.png': {'detections': [{'bbox': [94, 170, 211, 206],\n",
              "    'confidence': 0.8020449280738831}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars393.png'},\n",
              " 'Cars326.png': {'detections': [{'bbox': [118, 195, 264, 231],\n",
              "    'confidence': 0.8281866312026978}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars326.png'},\n",
              " 'Cars295.png': {'detections': [{'bbox': [238, 147, 271, 161],\n",
              "    'confidence': 0.36630555987358093}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars295.png'},\n",
              " 'Cars192.png': {'detections': [{'bbox': [111, 149, 209, 174],\n",
              "    'confidence': 0.8157917857170105}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars192.png'},\n",
              " 'Cars48.png': {'detections': [{'bbox': [99, 115, 283, 153],\n",
              "    'confidence': 0.7897834777832031}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars48.png'},\n",
              " 'Cars171.png': {'detections': [{'bbox': [189, 143, 243, 170],\n",
              "    'confidence': 0.8001904487609863}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars171.png'},\n",
              " 'Cars151.png': {'detections': [{'bbox': [60, 138, 113, 167],\n",
              "    'confidence': 0.68288654088974}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars151.png'},\n",
              " 'Cars27.png': {'detections': [{'bbox': [143, 126, 258, 158],\n",
              "    'confidence': 0.8445255160331726}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars27.png'},\n",
              " 'Cars174.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars174.png'},\n",
              " 'Cars97.png': {'detections': [{'bbox': [98, 100, 296, 191],\n",
              "    'confidence': 0.8699483275413513}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars97.png'},\n",
              " 'Cars221.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars221.png'},\n",
              " 'Cars177.png': {'detections': [{'bbox': [163, 165, 272, 192],\n",
              "    'confidence': 0.7826976776123047}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars177.png'},\n",
              " 'Cars2.png': {'detections': [{'bbox': [228, 172, 268, 195],\n",
              "    'confidence': 0.7725644707679749}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars2.png'},\n",
              " 'Cars404.png': {'detections': [{'bbox': [161, 207, 233, 244],\n",
              "    'confidence': 0.8799949288368225}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars404.png'},\n",
              " 'Cars391.png': {'detections': [{'bbox': [270, 163, 321, 192],\n",
              "    'confidence': 0.8020040392875671}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars391.png'},\n",
              " 'Cars432.png': {'detections': [{'bbox': [96, 257, 198, 284],\n",
              "    'confidence': 0.72709721326828}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars432.png'},\n",
              " 'Cars336.png': {'detections': [{'bbox': [118, 195, 264, 231],\n",
              "    'confidence': 0.8281866312026978}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars336.png'},\n",
              " 'Cars294.png': {'detections': [{'bbox': [141, 115, 220, 137],\n",
              "    'confidence': 0.7909739017486572}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars294.png'},\n",
              " 'Cars244.png': {'detections': [{'bbox': [19, 78, 366, 155],\n",
              "    'confidence': 0.7536574006080627}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars244.png'},\n",
              " 'Cars224.png': {'detections': [{'bbox': [177, 254, 239, 267],\n",
              "    'confidence': 0.6778998374938965},\n",
              "   {'bbox': [94, 181, 134, 197], 'confidence': 0.6060386300086975}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars224.png'},\n",
              " 'Cars127.png': {'detections': [{'bbox': [360, 167, 379, 181],\n",
              "    'confidence': 0.6565558314323425}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars127.png'},\n",
              " 'Cars195.png': {'detections': [{'bbox': [446, 226, 526, 246],\n",
              "    'confidence': 0.6563711166381836},\n",
              "   {'bbox': [436, 223, 532, 247], 'confidence': 0.4124797582626343}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars195.png'},\n",
              " 'Cars234.png': {'detections': [{'bbox': [157, 148, 246, 170],\n",
              "    'confidence': 0.7878599762916565}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars234.png'},\n",
              " 'Cars351.png': {'detections': [{'bbox': [248, 48, 367, 125],\n",
              "    'confidence': 0.8771949410438538}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars351.png'},\n",
              " 'Cars120.png': {'detections': [{'bbox': [160, 178, 251, 202],\n",
              "    'confidence': 0.8027167916297913}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars120.png'},\n",
              " 'Cars316.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars316.png'},\n",
              " 'Cars319.png': {'detections': [{'bbox': [165, 225, 229, 260],\n",
              "    'confidence': 0.4856383502483368}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars319.png'},\n",
              " 'Cars264.png': {'detections': [{'bbox': [217, 300, 294, 336],\n",
              "    'confidence': 0.7840595841407776}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars264.png'},\n",
              " 'Cars59.png': {'detections': [{'bbox': [323, 159, 374, 178],\n",
              "    'confidence': 0.6915295720100403}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars59.png'},\n",
              " 'Cars29.png': {'detections': [{'bbox': [143, 169, 213, 210],\n",
              "    'confidence': 0.8213142156600952},\n",
              "   {'bbox': [376, 190, 400, 216], 'confidence': 0.2949119806289673}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars29.png'},\n",
              " 'Cars160.png': {'detections': [{'bbox': [213, 136, 282, 169],\n",
              "    'confidence': 0.8459362387657166}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars160.png'},\n",
              " 'Cars412.png': {'detections': [{'bbox': [220, 172, 359, 202],\n",
              "    'confidence': 0.7657414078712463}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars412.png'},\n",
              " 'Cars101.png': {'detections': [{'bbox': [164, 201, 241, 219],\n",
              "    'confidence': 0.7405029535293579}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars101.png'},\n",
              " 'Cars53.png': {'detections': [{'bbox': [146, 186, 261, 213],\n",
              "    'confidence': 0.8189700841903687}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars53.png'},\n",
              " 'Cars334.png': {'detections': [{'bbox': [154, 145, 210, 160],\n",
              "    'confidence': 0.6342955827713013}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars334.png'},\n",
              " 'Cars186.png': {'detections': [{'bbox': [177, 154, 235, 170],\n",
              "    'confidence': 0.7423731088638306}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars186.png'},\n",
              " 'Cars346.png': {'detections': [{'bbox': [92, 185, 199, 218],\n",
              "    'confidence': 0.7708680033683777}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars346.png'},\n",
              " 'Cars299.png': {'detections': [{'bbox': [98, 136, 275, 175],\n",
              "    'confidence': 0.7925029993057251}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars299.png'},\n",
              " 'Cars332.png': {'detections': [{'bbox': [143, 126, 258, 158],\n",
              "    'confidence': 0.8445255160331726}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars332.png'},\n",
              " 'Cars260.png': {'detections': [{'bbox': [172, 112, 234, 127],\n",
              "    'confidence': 0.650536298751831}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars260.png'},\n",
              " 'Cars354.png': {'detections': [{'bbox': [66, 202, 99, 219],\n",
              "    'confidence': 0.7762556076049805}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars354.png'},\n",
              " 'Cars58.png': {'detections': [{'bbox': [153, 168, 239, 187],\n",
              "    'confidence': 0.7474674582481384}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars58.png'},\n",
              " 'Cars18.png': {'detections': [{'bbox': [312, 286, 405, 312],\n",
              "    'confidence': 0.7749935984611511}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars18.png'},\n",
              " 'Cars135.png': {'detections': [{'bbox': [260, 184, 317, 213],\n",
              "    'confidence': 0.76183021068573}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars135.png'},\n",
              " 'Cars405.png': {'detections': [{'bbox': [238, 205, 298, 229],\n",
              "    'confidence': 0.83521968126297}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars405.png'},\n",
              " 'Cars35.png': {'detections': [{'bbox': [91, 186, 137, 206],\n",
              "    'confidence': 0.7129663228988647}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars35.png'},\n",
              " 'Cars223.png': {'detections': [{'bbox': [346, 229, 406, 249],\n",
              "    'confidence': 0.45505234599113464}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars223.png'},\n",
              " 'Cars63.png': {'detections': [{'bbox': [55, 200, 90, 223],\n",
              "    'confidence': 0.7721107602119446}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars63.png'},\n",
              " 'Cars320.png': {'detections': [{'bbox': [70, 198, 261, 269],\n",
              "    'confidence': 0.8398513793945312}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars320.png'},\n",
              " 'Cars286.png': {'detections': [{'bbox': [202, 192, 285, 228],\n",
              "    'confidence': 0.7844870090484619}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars286.png'},\n",
              " 'Cars113.png': {'detections': [{'bbox': [148, 112, 304, 178],\n",
              "    'confidence': 0.8779211044311523}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars113.png'},\n",
              " 'Cars104.png': {'detections': [{'bbox': [191, 267, 240, 280],\n",
              "    'confidence': 0.6624191403388977}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars104.png'},\n",
              " 'Cars122.png': {'detections': [{'bbox': [197, 148, 251, 168],\n",
              "    'confidence': 0.7586898803710938}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars122.png'},\n",
              " 'Cars272.png': {'detections': [{'bbox': [171, 84, 316, 126],\n",
              "    'confidence': 0.8188796639442444}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars272.png'},\n",
              " 'Cars49.png': {'detections': [{'bbox': [269, 170, 314, 190],\n",
              "    'confidence': 0.7094956636428833}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars49.png'},\n",
              " 'Cars345.png': {'detections': [{'bbox': [173, 144, 247, 181],\n",
              "    'confidence': 0.8444665670394897}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars345.png'},\n",
              " 'Cars258.png': {'detections': [{'bbox': [159, 190, 227, 226],\n",
              "    'confidence': 0.7545034885406494}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars258.png'},\n",
              " 'Cars318.png': {'detections': [{'bbox': [99, 115, 283, 153],\n",
              "    'confidence': 0.7897834777832031}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars318.png'},\n",
              " 'Cars302.png': {'detections': [{'bbox': [232, 97, 434, 148],\n",
              "    'confidence': 0.8427431583404541},\n",
              "   {'bbox': [73, 48, 155, 90], 'confidence': 0.4541279077529907}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars302.png'},\n",
              " 'Cars159.png': {'detections': [{'bbox': [149, 180, 261, 207],\n",
              "    'confidence': 0.7891697883605957},\n",
              "   {'bbox': [390, 0, 400, 17], 'confidence': 0.26812705397605896}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars159.png'},\n",
              " 'Cars8.png': {'detections': [{'bbox': [206, 103, 303, 135],\n",
              "    'confidence': 0.8052502870559692}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars8.png'},\n",
              " 'Cars269.png': {'detections': [{'bbox': [110, 194, 147, 213],\n",
              "    'confidence': 0.6149221658706665}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars269.png'},\n",
              " 'Cars304.png': {'detections': [{'bbox': [142, 112, 221, 153],\n",
              "    'confidence': 0.8415510654449463}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars304.png'},\n",
              " 'Cars17.png': {'detections': [{'bbox': [303, 188, 347, 207],\n",
              "    'confidence': 0.714751124382019},\n",
              "   {'bbox': [130, 82, 154, 91], 'confidence': 0.2612462043762207}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars17.png'},\n",
              " 'Cars337.png': {'detections': [{'bbox': [119, 133, 137, 155],\n",
              "    'confidence': 0.39426538348197937},\n",
              "   {'bbox': [118, 130, 135, 148], 'confidence': 0.27346137166023254}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars337.png'},\n",
              " 'Cars349.png': {'detections': [{'bbox': [37, 224, 150, 250],\n",
              "    'confidence': 0.7159333229064941}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars349.png'},\n",
              " 'Cars178.png': {'detections': [{'bbox': [127, 180, 175, 205],\n",
              "    'confidence': 0.7868169546127319}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars178.png'},\n",
              " 'Cars1.png': {'detections': [{'bbox': [135, 125, 259, 161],\n",
              "    'confidence': 0.8512176871299744}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars1.png'},\n",
              " 'Cars247.png': {'detections': [{'bbox': [146, 25, 298, 147],\n",
              "    'confidence': 0.8350075483322144}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars247.png'},\n",
              " 'Cars377.png': {'detections': [{'bbox': [178, 138, 217, 159],\n",
              "    'confidence': 0.8185538053512573}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars377.png'},\n",
              " 'Cars243.png': {'detections': [{'bbox': [129, 170, 465, 236],\n",
              "    'confidence': 0.8079456686973572}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars243.png'},\n",
              " 'Cars196.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars196.png'},\n",
              " 'Cars355.png': {'detections': [{'bbox': [164, 154, 238, 189],\n",
              "    'confidence': 0.8552802801132202}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars355.png'},\n",
              " 'Cars52.png': {'detections': [{'bbox': [222, 180, 329, 209],\n",
              "    'confidence': 0.7688903212547302}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars52.png'},\n",
              " 'Cars284.png': {'detections': [{'bbox': [70, 198, 261, 269],\n",
              "    'confidence': 0.8398513793945312}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars284.png'},\n",
              " 'Cars250.png': {'detections': [{'bbox': [135, 125, 259, 161],\n",
              "    'confidence': 0.8512176871299744}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars250.png'},\n",
              " 'Cars184.png': {'detections': [{'bbox': [165, 145, 211, 156],\n",
              "    'confidence': 0.539747416973114}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars184.png'},\n",
              " 'Cars312.png': {'detections': [{'bbox': [151, 79, 511, 252],\n",
              "    'confidence': 0.8444080352783203}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars312.png'},\n",
              " 'Cars401.png': {'detections': [{'bbox': [159, 222, 236, 241],\n",
              "    'confidence': 0.7552739381790161}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars401.png'},\n",
              " 'Cars297.png': {'detections': [{'bbox': [157, 148, 246, 170],\n",
              "    'confidence': 0.7878599762916565}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars297.png'},\n",
              " 'Cars22.png': {'detections': [{'bbox': [206, 103, 258, 115],\n",
              "    'confidence': 0.45620569586753845}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars22.png'},\n",
              " 'Cars213.png': {'detections': [{'bbox': [146, 158, 223, 183],\n",
              "    'confidence': 0.5466798543930054},\n",
              "   {'bbox': [144, 158, 252, 185], 'confidence': 0.4920719265937805}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars213.png'},\n",
              " 'Cars307.png': {'detections': [{'bbox': [174, 165, 436, 219],\n",
              "    'confidence': 0.8705874681472778}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars307.png'},\n",
              " 'Cars416.png': {'detections': [{'bbox': [152, 205, 234, 221],\n",
              "    'confidence': 0.6329587697982788}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars416.png'},\n",
              " 'Cars421.png': {'detections': [{'bbox': [94, 163, 126, 182],\n",
              "    'confidence': 0.7056934237480164}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars421.png'},\n",
              " 'Cars190.png': {'detections': [{'bbox': [152, 212, 248, 236],\n",
              "    'confidence': 0.7554317712783813}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars190.png'},\n",
              " 'Cars107.png': {'detections': [{'bbox': [141, 114, 315, 163],\n",
              "    'confidence': 0.8270980715751648}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars107.png'},\n",
              " 'Cars360.png': {'detections': [{'bbox': [51, 166, 94, 200],\n",
              "    'confidence': 0.8655086755752563}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars360.png'},\n",
              " 'Cars128.png': {'detections': [{'bbox': [103, 67, 304, 159],\n",
              "    'confidence': 0.8670428395271301}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars128.png'},\n",
              " 'Cars329.png': {'detections': [{'bbox': [168, 141, 226, 174],\n",
              "    'confidence': 0.835828423500061}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars329.png'},\n",
              " 'Cars330.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars330.png'},\n",
              " 'Cars231.png': {'detections': [{'bbox': [70, 162, 132, 179],\n",
              "    'confidence': 0.8368828892707825}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars231.png'},\n",
              " 'Cars131.png': {'detections': [{'bbox': [22, 4, 493, 266],\n",
              "    'confidence': 0.7620513439178467},\n",
              "   {'bbox': [0, 25, 416, 251], 'confidence': 0.42520105838775635},\n",
              "   {'bbox': [6, 130, 495, 300], 'confidence': 0.3946622312068939}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars131.png'},\n",
              " 'Cars150.png': {'detections': [{'bbox': [118, 195, 264, 231],\n",
              "    'confidence': 0.8281866312026978}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars150.png'},\n",
              " 'Cars111.png': {'detections': [{'bbox': [323, 165, 476, 206],\n",
              "    'confidence': 0.8180002570152283}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars111.png'},\n",
              " 'Cars342.png': {'detections': [{'bbox': [197, 148, 251, 168],\n",
              "    'confidence': 0.7586898803710938}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars342.png'},\n",
              " 'Cars3.png': {'detections': [{'bbox': [143, 126, 258, 158],\n",
              "    'confidence': 0.8445255160331726}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars3.png'},\n",
              " 'Cars376.png': {'detections': [{'bbox': [160, 178, 251, 202],\n",
              "    'confidence': 0.8027167916297913}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars376.png'},\n",
              " 'Cars175.png': {'detections': [{'bbox': [295, 252, 460, 366],\n",
              "    'confidence': 0.8181526064872742}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars175.png'},\n",
              " 'Cars69.png': {'detections': [{'bbox': [76, 150, 124, 175],\n",
              "    'confidence': 0.6695166826248169}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars69.png'},\n",
              " 'Cars24.png': {'detections': [{'bbox': [164, 201, 241, 219],\n",
              "    'confidence': 0.7405029535293579}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars24.png'},\n",
              " 'Cars169.png': {'detections': [{'bbox': [113, 74, 229, 101],\n",
              "    'confidence': 0.7517739534378052}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars169.png'},\n",
              " 'Cars161.png': {'detections': [{'bbox': [312, 286, 405, 312],\n",
              "    'confidence': 0.7749935984611511}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars161.png'},\n",
              " 'Cars233.png': {'detections': [{'bbox': [182, 56, 257, 80],\n",
              "    'confidence': 0.7471789717674255}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars233.png'},\n",
              " 'Cars375.png': {'detections': [{'bbox': [142, 114, 297, 144],\n",
              "    'confidence': 0.7322198152542114}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars375.png'},\n",
              " 'Cars241.png': {'detections': [{'bbox': [124, 139, 245, 196],\n",
              "    'confidence': 0.8103771805763245}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars241.png'},\n",
              " 'Cars65.png': {'detections': [{'bbox': [205, 201, 300, 259],\n",
              "    'confidence': 0.8113250732421875}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars65.png'},\n",
              " 'Cars277.png': {'detections': [{'bbox': [45, 218, 71, 227],\n",
              "    'confidence': 0.4790080785751343}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars277.png'},\n",
              " 'Cars411.png': {'detections': [{'bbox': [159, 152, 246, 195],\n",
              "    'confidence': 0.8533040881156921}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars411.png'},\n",
              " 'Cars40.png': {'detections': [{'bbox': [260, 184, 317, 213],\n",
              "    'confidence': 0.76183021068573}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars40.png'},\n",
              " 'Cars430.png': {'detections': [{'bbox': [38, 159, 116, 197],\n",
              "    'confidence': 0.8421564102172852}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars430.png'},\n",
              " 'Cars240.png': {'detections': [{'bbox': [196, 115, 255, 132],\n",
              "    'confidence': 0.42225751280784607}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars240.png'},\n",
              " 'Cars214.png': {'detections': [{'bbox': [74, 128, 97, 141],\n",
              "    'confidence': 0.5033915042877197}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars214.png'},\n",
              " 'Cars187.png': {'detections': [{'bbox': [99, 115, 283, 153],\n",
              "    'confidence': 0.7897834777832031}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars187.png'},\n",
              " 'Cars207.png': {'detections': [{'bbox': [254, 227, 379, 262],\n",
              "    'confidence': 0.763895571231842},\n",
              "   {'bbox': [251, 213, 383, 268], 'confidence': 0.5128156542778015}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars207.png'},\n",
              " 'Cars98.png': {'detections': [{'bbox': [84, 195, 247, 260],\n",
              "    'confidence': 0.8564233183860779}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars98.png'},\n",
              " 'Cars129.png': {'detections': [{'bbox': [205, 219, 283, 265],\n",
              "    'confidence': 0.7429083585739136}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars129.png'},\n",
              " 'Cars143.png': {'detections': [{'bbox': [94, 196, 132, 208],\n",
              "    'confidence': 0.6027156114578247},\n",
              "   {'bbox': [317, 195, 349, 207], 'confidence': 0.5596046447753906}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars143.png'},\n",
              " 'Cars132.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars132.png'},\n",
              " 'Cars356.png': {'detections': [{'bbox': [243, 216, 363, 273],\n",
              "    'confidence': 0.8174511790275574}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars356.png'},\n",
              " 'Cars219.png': {'detections': [{'bbox': [129, 171, 463, 237],\n",
              "    'confidence': 0.8129261136054993}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars219.png'},\n",
              " 'Cars397.png': {'detections': [{'bbox': [143, 169, 213, 210],\n",
              "    'confidence': 0.8213142156600952},\n",
              "   {'bbox': [376, 190, 400, 216], 'confidence': 0.2949119806289673}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars397.png'},\n",
              " 'Cars254.png': {'detections': [{'bbox': [165, 174, 234, 207],\n",
              "    'confidence': 0.8276143670082092}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars254.png'},\n",
              " 'Cars83.png': {'detections': [{'bbox': [251, 295, 327, 336],\n",
              "    'confidence': 0.8279847502708435}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars83.png'},\n",
              " 'Cars165.png': {'detections': [{'bbox': [213, 217, 293, 246],\n",
              "    'confidence': 0.690424382686615},\n",
              "   {'bbox': [462, 0, 589, 65], 'confidence': 0.27226585149765015}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars165.png'},\n",
              " 'Cars116.png': {'detections': [{'bbox': [148, 216, 265, 244],\n",
              "    'confidence': 0.8051074147224426}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars116.png'},\n",
              " 'Cars229.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars229.png'},\n",
              " 'Cars141.png': {'detections': [{'bbox': [267, 171, 303, 189],\n",
              "    'confidence': 0.5632159113883972}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars141.png'},\n",
              " 'Cars185.png': {'detections': [{'bbox': [152, 146, 291, 199],\n",
              "    'confidence': 0.8682052493095398}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars185.png'},\n",
              " 'Cars173.png': {'detections': [{'bbox': [168, 117, 251, 162],\n",
              "    'confidence': 0.7868676781654358}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars173.png'},\n",
              " 'Cars389.png': {'detections': [{'bbox': [81, 303, 222, 368],\n",
              "    'confidence': 0.8210427165031433}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars389.png'},\n",
              " 'Cars331.png': {'detections': [{'bbox': [156, 223, 222, 238],\n",
              "    'confidence': 0.5584135055541992}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars331.png'},\n",
              " 'Cars211.png': {'detections': [{'bbox': [17, 51, 400, 233],\n",
              "    'confidence': 0.8269314169883728}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars211.png'},\n",
              " 'Cars100.png': {'detections': [{'bbox': [166, 110, 212, 130],\n",
              "    'confidence': 0.29725149273872375}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars100.png'},\n",
              " 'Cars12.png': {'detections': [{'bbox': [120, 83, 276, 115],\n",
              "    'confidence': 0.8301142454147339}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars12.png'},\n",
              " 'Cars56.png': {'detections': [{'bbox': [88, 80, 340, 145],\n",
              "    'confidence': 0.8483116030693054}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars56.png'},\n",
              " 'Cars43.png': {'detections': [{'bbox': [141, 114, 315, 163],\n",
              "    'confidence': 0.8270980715751648}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars43.png'},\n",
              " 'Cars384.png': {'detections': [{'bbox': [220, 195, 272, 232],\n",
              "    'confidence': 0.6774593591690063}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars384.png'},\n",
              " 'Cars47.png': {'detections': [{'bbox': [7, 141, 47, 163],\n",
              "    'confidence': 0.7339373826980591}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars47.png'},\n",
              " 'Cars68.png': {'detections': [{'bbox': [189, 143, 243, 170],\n",
              "    'confidence': 0.8001904487609863}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars68.png'},\n",
              " 'Cars263.png': {'detections': [{'bbox': [127, 263, 231, 290],\n",
              "    'confidence': 0.719561755657196}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars263.png'},\n",
              " 'Cars20.png': {'detections': [{'bbox': [19, 131, 46, 159],\n",
              "    'confidence': 0.39099791646003723}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars20.png'},\n",
              " 'Cars158.png': {'detections': [{'bbox': [95, 120, 294, 210],\n",
              "    'confidence': 0.8619771599769592}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars158.png'},\n",
              " 'Cars396.png': {'detections': [{'bbox': [182, 264, 269, 287],\n",
              "    'confidence': 0.8342751860618591}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars396.png'},\n",
              " 'Cars372.png': {'detections': [{'bbox': [226, 276, 355, 311],\n",
              "    'confidence': 0.7255313396453857}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars372.png'},\n",
              " 'Cars259.png': {'detections': [{'bbox': [323, 165, 476, 206],\n",
              "    'confidence': 0.8180002570152283}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars259.png'},\n",
              " 'Cars28.png': {'detections': [],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars28.png'},\n",
              " 'Cars5.png': {'detections': [{'bbox': [207, 224, 235, 246],\n",
              "    'confidence': 0.3348240554332733}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars5.png'},\n",
              " 'Cars419.png': {'detections': [{'bbox': [198, 197, 350, 241],\n",
              "    'confidence': 0.8762956857681274}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars419.png'},\n",
              " 'Cars67.png': {'detections': [{'bbox': [186, 223, 328, 248],\n",
              "    'confidence': 0.7694457769393921}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars67.png'},\n",
              " 'Cars365.png': {'detections': [{'bbox': [295, 204, 375, 225],\n",
              "    'confidence': 0.7011821269989014}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars365.png'},\n",
              " 'Cars270.png': {'detections': [{'bbox': [73, 172, 123, 195],\n",
              "    'confidence': 0.7885910868644714}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars270.png'},\n",
              " 'Cars228.png': {'detections': [{'bbox': [81, 125, 116, 143],\n",
              "    'confidence': 0.7284059524536133}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars228.png'},\n",
              " 'Cars144.png': {'detections': [{'bbox': [104, 114, 210, 148],\n",
              "    'confidence': 0.799880862236023}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars144.png'},\n",
              " 'Cars374.png': {'detections': [{'bbox': [353, 118, 441, 142],\n",
              "    'confidence': 0.7353336811065674}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars374.png'},\n",
              " 'Cars271.png': {'detections': [{'bbox': [265, 140, 318, 162],\n",
              "    'confidence': 0.7826051712036133}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars271.png'},\n",
              " 'Cars306.png': {'detections': [{'bbox': [142, 281, 249, 309],\n",
              "    'confidence': 0.7948747277259827}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars306.png'},\n",
              " 'Cars399.png': {'detections': [{'bbox': [103, 67, 304, 159],\n",
              "    'confidence': 0.8670428395271301}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars399.png'},\n",
              " 'Cars324.png': {'detections': [{'bbox': [150, 138, 255, 158],\n",
              "    'confidence': 0.8386558294296265}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars324.png'},\n",
              " 'Cars25.png': {'detections': [{'bbox': [178, 138, 217, 159],\n",
              "    'confidence': 0.8185538053512573}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars25.png'},\n",
              " 'Cars201.png': {'detections': [{'bbox': [220, 172, 359, 202],\n",
              "    'confidence': 0.7657414078712463}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars201.png'},\n",
              " 'Cars96.png': {'detections': [{'bbox': [135, 125, 259, 161],\n",
              "    'confidence': 0.8512176871299744}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars96.png'},\n",
              " 'Cars200.png': {'detections': [{'bbox': [92, 185, 199, 218],\n",
              "    'confidence': 0.7708680033683777}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars200.png'},\n",
              " 'Cars245.png': {'detections': [{'bbox': [89, 111, 164, 132],\n",
              "    'confidence': 0.7137470841407776}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars245.png'},\n",
              " 'Cars14.png': {'detections': [{'bbox': [99, 115, 283, 153],\n",
              "    'confidence': 0.7897834777832031}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars14.png'},\n",
              " 'Cars134.png': {'detections': [{'bbox': [78, 153, 134, 173],\n",
              "    'confidence': 0.8162646293640137}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars134.png'},\n",
              " 'Cars206.png': {'detections': [{'bbox': [95, 185, 162, 203],\n",
              "    'confidence': 0.7308222055435181}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars206.png'},\n",
              " 'Cars423.png': {'detections': [{'bbox': [165, 158, 282, 182],\n",
              "    'confidence': 0.8284485936164856}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars423.png'},\n",
              " 'Cars89.png': {'detections': [{'bbox': [308, 206, 344, 220],\n",
              "    'confidence': 0.6992784738540649}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars89.png'},\n",
              " 'Cars370.png': {'detections': [{'bbox': [284, 248, 422, 278],\n",
              "    'confidence': 0.8287874460220337}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars370.png'},\n",
              " 'Cars163.png': {'detections': [{'bbox': [220, 172, 359, 202],\n",
              "    'confidence': 0.7657414078712463}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars163.png'},\n",
              " 'Cars235.png': {'detections': [{'bbox': [152, 142, 250, 165],\n",
              "    'confidence': 0.817571222782135}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars235.png'},\n",
              " 'Cars109.png': {'detections': [{'bbox': [115, 115, 277, 152],\n",
              "    'confidence': 0.8681740164756775}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars109.png'},\n",
              " 'Cars130.png': {'detections': [{'bbox': [89, 111, 164, 132],\n",
              "    'confidence': 0.7137470841407776}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars130.png'},\n",
              " 'Cars114.png': {'detections': [{'bbox': [22, 4, 493, 266],\n",
              "    'confidence': 0.7620513439178467},\n",
              "   {'bbox': [0, 25, 416, 251], 'confidence': 0.42520105838775635},\n",
              "   {'bbox': [6, 130, 495, 300], 'confidence': 0.3946622312068939}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars114.png'},\n",
              " 'Cars91.png': {'detections': [{'bbox': [269, 170, 314, 190],\n",
              "    'confidence': 0.7094956636428833}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars91.png'},\n",
              " 'Cars417.png': {'detections': [{'bbox': [93, 146, 279, 187],\n",
              "    'confidence': 0.7495313286781311}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars417.png'},\n",
              " 'Cars36.png': {'detections': [{'bbox': [202, 192, 285, 228],\n",
              "    'confidence': 0.7844870090484619}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars36.png'},\n",
              " 'Cars102.png': {'detections': [{'bbox': [60, 144, 324, 201],\n",
              "    'confidence': 0.8149523735046387}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars102.png'},\n",
              " 'Cars368.png': {'detections': [{'bbox': [173, 173, 227, 202],\n",
              "    'confidence': 0.8406460881233215}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars368.png'},\n",
              " 'Cars86.png': {'detections': [{'bbox': [335, 173, 446, 203],\n",
              "    'confidence': 0.735286295413971}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars86.png'},\n",
              " 'Cars110.png': {'detections': [{'bbox': [282, 133, 329, 158],\n",
              "    'confidence': 0.7662307024002075}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars110.png'},\n",
              " 'Cars255.png': {'detections': [{'bbox': [114, 156, 272, 190],\n",
              "    'confidence': 0.8438668847084045}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars255.png'},\n",
              " 'Cars292.png': {'detections': [{'bbox': [91, 186, 137, 206],\n",
              "    'confidence': 0.7129663228988647}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars292.png'},\n",
              " 'Cars54.png': {'detections': [{'bbox': [148, 61, 256, 118],\n",
              "    'confidence': 0.8926308155059814}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars54.png'},\n",
              " 'Cars199.png': {'detections': [{'bbox': [56, 90, 307, 155],\n",
              "    'confidence': 0.8027385473251343}],\n",
              "  'original_path': 'dataset/preprocessed_images/Cars199.png'}}"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1FnAUEecxPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}